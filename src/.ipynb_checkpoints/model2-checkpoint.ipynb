{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备工作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T08:32:04.067556Z",
     "start_time": "2021-01-04T08:32:04.055839Z"
    }
   },
   "outputs": [],
   "source": [
    "train_path = \"../data/train.txt\"\n",
    "test_path = \"../data/test.txt\"\n",
    "train_process_path = \"../data/train_precessed.txt\"\n",
    "test_process_path = \"../data/test_processed.txt\"\n",
    "\n",
    "labels_dict = {'Cause-Effect': '0', 'Instrument-Agency': '1', 'Product-Producer': '2',\n",
    "                   'Content-Container': '3', 'Entity-Origin': '4', 'Entity-Destination': '5',\n",
    "                   'Component-Whole': '6', 'Member-Collection': '7', 'Message-Topic': '8',\n",
    "                   'Other': '9'}\n",
    "\n",
    "# 定义类别列表\n",
    "LABEL_INDEX = ['Cause-Effect', 'Instrument-Agency', 'Product-Producer',\n",
    "               'Content-Container', 'Entity-Origin', 'Entity-Destination',\n",
    "               'Component-Whole', 'Member-Collection', 'Message-Topic', 'Other']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T08:36:31.991025Z",
     "start_time": "2021-01-04T08:36:31.985527Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import random\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import keras as krs\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载测试数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-01T06:20:09.863825Z",
     "start_time": "2021-01-01T06:20:09.860318Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_test_data(filename):\n",
    "    text_list = []\n",
    "    print(\"正在加载文本测试数据...\")\n",
    "    with open(filename, \"r\") as f:\n",
    "        for line in f.readlines():\n",
    "            item = line.strip().split('\\t')\n",
    "            text_list.append(item[0].lower())\n",
    "        \n",
    "    print(\"共加载了 %s 条数据\" % len(text_list))\n",
    "    return text_list\n",
    "\n",
    "# 读取测试集\n",
    "test_data_path = '../data/test_processed.txt'\n",
    "\n",
    "texts_test = load_test_data(test_data_path)\n",
    "texts_test = [\".\".join(t.lower().split(' ')) for t in texts_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T12:45:52.110992Z",
     "start_time": "2021-01-04T12:45:51.731216Z"
    }
   },
   "outputs": [],
   "source": [
    "# word2vec 词袋化\n",
    "vocab_processor = tf.contrib.learn.preprocessing.VocabularyProcessor(max_sequence_length,min_frequency=0)\n",
    "\n",
    "text_processed_test = np.array(list(vocab_processor.fit_transform(texts_test)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T12:45:52.771471Z",
     "start_time": "2021-01-04T12:45:52.768341Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7715"
      ]
     },
     "execution_count": 564,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab_dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载训练数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T09:07:53.622961Z",
     "start_time": "2021-01-04T09:07:53.618396Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    text_list = []\n",
    "    label_list = []\n",
    "    print(\"正在加载文本数据...\")\n",
    "    with open(filename, \"r\") as f:\n",
    "        for line in f.readlines():\n",
    "            item = line.strip().split('\\t')\n",
    "            label_list.append(item[2])\n",
    "            text_list.append(item[3])\n",
    "        \n",
    "    target = np.array(label_list)\n",
    "    print(\"共加载了 %s 条数据\" % target.shape)\n",
    "    return text_list, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T09:14:33.849233Z",
     "start_time": "2021-01-04T09:14:33.830324Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在加载文本数据...\n",
      "共加载了 6400 条数据\n"
     ]
    }
   ],
   "source": [
    "train_data_path = '../data/train_precessed.txt'\n",
    "test_data_path = '../data/test_processed.txt'\n",
    "\n",
    "texts, labels_tmp = load_data(train_data_path)\n",
    "labels_dict = {'Cause-Effect': '0', 'Instrument-Agency': '1', 'Product-Producer': '2',\n",
    "                   'Content-Container': '3', 'Entity-Origin': '4', 'Entity-Destination': '5',\n",
    "                   'Component-Whole': '6', 'Member-Collection': '7', 'Message-Topic': '8',\n",
    "                   'Other': '9'}\n",
    "\n",
    "texts = [texts[i].lower() for i in range(len(texts))]\n",
    "raw_texts = texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 经检查，测试集最长的句子包含83个词，以83作为句子编码的长度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T09:14:31.280514Z",
     "start_time": "2021-01-04T09:14:31.271107Z"
    }
   },
   "outputs": [],
   "source": [
    "max_sequence_length = 83  # 每个样本保留83个词的长度\n",
    "labels = []\n",
    "for i in range(len(labels_tmp)):\n",
    "    lable = labels_dict[labels_tmp[i]]\n",
    "    labels.append(lable)\n",
    "labels = np.array(labels)\n",
    "raw_labels = labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练十个BiLSTM模型，最后通过投票得出预测结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T11:19:22.851346Z",
     "start_time": "2021-01-04T11:19:05.427885Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/ipykernel_launcher.py:16: UserWarning: The `dropout` argument is no longer support in `Embedding`. You can apply a `keras.layers.SpatialDropout1D` layer right after the `Embedding` layer to get the same behavior.\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "embedding_size = 100\n",
    "\n",
    "models = []\n",
    "BATCH_SIZE = 128\n",
    "EPOCH = 25\n",
    "ckpt = krs.callbacks.ModelCheckpoint('./temp/ckpt', monitor='val_categorical_accuracy', verbose=1,\n",
    "                                          save_best_only=True, save_weights_only=False, period=1)\n",
    "earlystop = krs.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.0001,\n",
    "                                             patience=10, verbose=1)\n",
    "# patience: n次acc未增长则终止训练\n",
    "\n",
    "for i in range(10):\n",
    "    model = krs.Sequential()\n",
    "    model.add(krs.layers.Embedding(len(dict.items()),\n",
    "                embedding_size, input_length = max_sequence_length,\n",
    "                 mask_zero= True  ,dropout = 0.2  ))\n",
    "    model.add(krs.layers.Bidirectional(krs.layers.LSTM(100,dropout = 0.5)))\n",
    "    model.add(krs.layers.Dense(10))\n",
    "    model.add(krs.layers.Activation(\"softmax\"))\n",
    "    #model.summary()\n",
    "    model.compile(loss = \"categorical_crossentropy\", optimizer= \"adam\", metrics=[\"categorical_accuracy\"])\n",
    "    models.append(model)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T11:19:22.892404Z",
     "start_time": "2021-01-04T11:19:22.887803Z"
    }
   },
   "outputs": [],
   "source": [
    "# 衰减学习率\n",
    "class LearningRateExponentialDecay:\n",
    "    def __init__(self, initial_learning_rate, decay_epochs, decay_rate):\n",
    "        self.initial_learning_rate = initial_learning_rate\n",
    "        self.decay_epochs = decay_epochs\n",
    "        self.decay_rate = decay_rate\n",
    "\n",
    "    def __call__(self, epoch):\n",
    "        dtype = type(self.initial_learning_rate)\n",
    "        decay_epochs = np.array(self.decay_epochs).astype(dtype)\n",
    "        decay_rate = np.array(self.decay_rate).astype(dtype)\n",
    "        epoch = np.array(epoch).astype(dtype)\n",
    "        p = epoch / decay_epochs\n",
    "        learning_rate = self.initial_learning_rate * np.power(decay_rate, p)\n",
    "        return learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T11:19:22.929059Z",
     "start_time": "2021-01-04T11:19:22.926613Z"
    }
   },
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T11:52:12.361671Z",
     "start_time": "2021-01-04T11:19:33.065135Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5760 samples, validate on 640 samples\n",
      "Epoch 1/25\n",
      "\n",
      "Epoch 00001: LearningRateScheduler setting learning rate to 0.0003.\n",
      "5760/5760 [==============================] - 17s 3ms/step - loss: 2.2849 - categorical_accuracy: 0.1521 - val_loss: 2.2558 - val_categorical_accuracy: 0.1469\n",
      "\n",
      "Epoch 00001: val_categorical_accuracy improved from -inf to 0.14687, saving model to ./temp/ckpt\n",
      "Epoch 2/25\n",
      "\n",
      "Epoch 00002: LearningRateScheduler setting learning rate to 0.0002973341922389158.\n",
      "5760/5760 [==============================] - 10s 2ms/step - loss: 2.2080 - categorical_accuracy: 0.1793 - val_loss: 2.1412 - val_categorical_accuracy: 0.2484\n",
      "\n",
      "Epoch 00002: val_categorical_accuracy improved from 0.14687 to 0.24844, saving model to ./temp/ckpt\n",
      "Epoch 3/25\n",
      "\n",
      "Epoch 00003: LearningRateScheduler setting learning rate to 0.0002946920729145618.\n",
      "5760/5760 [==============================] - 11s 2ms/step - loss: 2.0190 - categorical_accuracy: 0.3165 - val_loss: 1.9250 - val_categorical_accuracy: 0.3297\n",
      "\n",
      "Epoch 00003: val_categorical_accuracy improved from 0.24844 to 0.32969, saving model to ./temp/ckpt\n",
      "Epoch 4/25\n",
      "\n",
      "Epoch 00004: LearningRateScheduler setting learning rate to 0.0002920734315308764.\n",
      "5760/5760 [==============================] - 11s 2ms/step - loss: 1.8082 - categorical_accuracy: 0.3816 - val_loss: 1.7873 - val_categorical_accuracy: 0.3562\n",
      "\n",
      "Epoch 00004: val_categorical_accuracy improved from 0.32969 to 0.35625, saving model to ./temp/ckpt\n",
      "Epoch 5/25\n",
      "\n",
      "Epoch 00005: LearningRateScheduler setting learning rate to 0.00028947805946227145.\n",
      "5760/5760 [==============================] - 11s 2ms/step - loss: 1.6446 - categorical_accuracy: 0.4307 - val_loss: 1.7111 - val_categorical_accuracy: 0.4000\n",
      "\n",
      "Epoch 00005: val_categorical_accuracy improved from 0.35625 to 0.40000, saving model to ./temp/ckpt\n",
      "Epoch 6/25\n",
      "\n",
      "Epoch 00006: LearningRateScheduler setting learning rate to 0.0002869057499370111.\n",
      "5760/5760 [==============================] - 11s 2ms/step - loss: 1.4887 - categorical_accuracy: 0.4885 - val_loss: 1.6637 - val_categorical_accuracy: 0.4313\n",
      "\n",
      "Epoch 00006: val_categorical_accuracy improved from 0.40000 to 0.43125, saving model to ./temp/ckpt\n",
      "Epoch 7/25\n",
      "\n",
      "Epoch 00007: LearningRateScheduler setting learning rate to 0.00028435629802073855.\n",
      "5760/5760 [==============================] - 11s 2ms/step - loss: 1.3634 - categorical_accuracy: 0.5252 - val_loss: 1.6484 - val_categorical_accuracy: 0.4516\n",
      "\n",
      "Epoch 00007: val_categorical_accuracy improved from 0.43125 to 0.45156, saving model to ./temp/ckpt\n",
      "Epoch 8/25\n",
      "\n",
      "Epoch 00008: LearningRateScheduler setting learning rate to 0.00028182950060014905.\n",
      "5760/5760 [==============================] - 10s 2ms/step - loss: 1.2460 - categorical_accuracy: 0.5675 - val_loss: 1.6467 - val_categorical_accuracy: 0.4625\n",
      "\n",
      "Epoch 00008: val_categorical_accuracy improved from 0.45156 to 0.46250, saving model to ./temp/ckpt\n",
      "Epoch 9/25\n",
      "\n",
      "Epoch 00009: LearningRateScheduler setting learning rate to 0.0002793251563668079.\n",
      "5760/5760 [==============================] - 10s 2ms/step - loss: 1.1467 - categorical_accuracy: 0.6069 - val_loss: 1.6731 - val_categorical_accuracy: 0.4656\n",
      "\n",
      "Epoch 00009: val_categorical_accuracy improved from 0.46250 to 0.46562, saving model to ./temp/ckpt\n",
      "Epoch 10/25\n",
      "\n",
      "Epoch 00010: LearningRateScheduler setting learning rate to 0.00027684306580111226.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 1.0547 - categorical_accuracy: 0.6332 - val_loss: 1.7027 - val_categorical_accuracy: 0.4672\n",
      "\n",
      "Epoch 00010: val_categorical_accuracy improved from 0.46562 to 0.46719, saving model to ./temp/ckpt\n",
      "Epoch 11/25\n",
      "\n",
      "Epoch 00011: LearningRateScheduler setting learning rate to 0.0002743830311563958.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 0.9627 - categorical_accuracy: 0.6750 - val_loss: 1.7760 - val_categorical_accuracy: 0.4594\n",
      "\n",
      "Epoch 00011: val_categorical_accuracy did not improve from 0.46719\n",
      "Epoch 12/25\n",
      "\n",
      "Epoch 00012: LearningRateScheduler setting learning rate to 0.00027194485644317407.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 0.8865 - categorical_accuracy: 0.7049 - val_loss: 1.7691 - val_categorical_accuracy: 0.4500\n",
      "\n",
      "Epoch 00012: val_categorical_accuracy did not improve from 0.46719\n",
      "Epoch 13/25\n",
      "\n",
      "Epoch 00013: LearningRateScheduler setting learning rate to 0.0002695283474135303.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 0.8223 - categorical_accuracy: 0.7269 - val_loss: 1.8038 - val_categorical_accuracy: 0.4750\n",
      "\n",
      "Epoch 00013: val_categorical_accuracy improved from 0.46719 to 0.47500, saving model to ./temp/ckpt\n",
      "Epoch 14/25\n",
      "\n",
      "Epoch 00014: LearningRateScheduler setting learning rate to 0.0002671333115456397.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 0.7656 - categorical_accuracy: 0.7552 - val_loss: 1.8583 - val_categorical_accuracy: 0.4594\n",
      "\n",
      "Epoch 00014: val_categorical_accuracy did not improve from 0.47500\n",
      "Epoch 15/25\n",
      "\n",
      "Epoch 00015: LearningRateScheduler setting learning rate to 0.0002647595580284314.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 0.7026 - categorical_accuracy: 0.7833 - val_loss: 1.9152 - val_categorical_accuracy: 0.4672\n",
      "\n",
      "Epoch 00015: val_categorical_accuracy did not improve from 0.47500\n",
      "Epoch 16/25\n",
      "\n",
      "Epoch 00016: LearningRateScheduler setting learning rate to 0.00026240689774638675.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 0.6520 - categorical_accuracy: 0.7957 - val_loss: 1.9586 - val_categorical_accuracy: 0.4719\n",
      "\n",
      "Epoch 00016: val_categorical_accuracy did not improve from 0.47500\n",
      "Epoch 17/25\n",
      "\n",
      "Epoch 00017: LearningRateScheduler setting learning rate to 0.00026007514326447225.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 0.6065 - categorical_accuracy: 0.8153 - val_loss: 2.0131 - val_categorical_accuracy: 0.4750\n",
      "\n",
      "Epoch 00017: val_categorical_accuracy did not improve from 0.47500\n",
      "Epoch 18/25\n",
      "\n",
      "Epoch 00018: LearningRateScheduler setting learning rate to 0.00025776410881320726.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 0.5729 - categorical_accuracy: 0.8337 - val_loss: 1.9802 - val_categorical_accuracy: 0.4750\n",
      "\n",
      "Epoch 00018: val_categorical_accuracy did not improve from 0.47500\n",
      "Epoch 00018: early stopping\n",
      "models num: 1\n",
      "Train on 5760 samples, validate on 640 samples\n",
      "Epoch 1/25\n",
      "\n",
      "Epoch 00001: LearningRateScheduler setting learning rate to 0.0003.\n",
      "5760/5760 [==============================] - 17s 3ms/step - loss: 2.2860 - categorical_accuracy: 0.1503 - val_loss: 2.2635 - val_categorical_accuracy: 0.1719\n",
      "\n",
      "Epoch 00001: val_categorical_accuracy did not improve from 0.47500\n",
      "Epoch 2/25\n",
      "\n",
      "Epoch 00002: LearningRateScheduler setting learning rate to 0.0002973341922389158.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 2.2175 - categorical_accuracy: 0.2007 - val_loss: 2.1687 - val_categorical_accuracy: 0.2453\n",
      "\n",
      "Epoch 00002: val_categorical_accuracy did not improve from 0.47500\n",
      "Epoch 3/25\n",
      "\n",
      "Epoch 00003: LearningRateScheduler setting learning rate to 0.0002946920729145618.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 2.0409 - categorical_accuracy: 0.3035 - val_loss: 1.9325 - val_categorical_accuracy: 0.3328\n",
      "\n",
      "Epoch 00003: val_categorical_accuracy did not improve from 0.47500\n",
      "Epoch 4/25\n",
      "\n",
      "Epoch 00004: LearningRateScheduler setting learning rate to 0.0002920734315308764.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 1.7993 - categorical_accuracy: 0.3762 - val_loss: 1.8002 - val_categorical_accuracy: 0.3625\n",
      "\n",
      "Epoch 00004: val_categorical_accuracy did not improve from 0.47500\n",
      "Epoch 5/25\n",
      "\n",
      "Epoch 00005: LearningRateScheduler setting learning rate to 0.00028947805946227145.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 1.6162 - categorical_accuracy: 0.4486 - val_loss: 1.6995 - val_categorical_accuracy: 0.4062\n",
      "\n",
      "Epoch 00005: val_categorical_accuracy did not improve from 0.47500\n",
      "Epoch 6/25\n",
      "\n",
      "Epoch 00006: LearningRateScheduler setting learning rate to 0.0002869057499370111.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 1.4632 - categorical_accuracy: 0.5010 - val_loss: 1.6570 - val_categorical_accuracy: 0.4203\n",
      "\n",
      "Epoch 00006: val_categorical_accuracy did not improve from 0.47500\n",
      "Epoch 7/25\n",
      "\n",
      "Epoch 00007: LearningRateScheduler setting learning rate to 0.00028435629802073855.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5760/5760 [==============================] - 9s 2ms/step - loss: 1.3429 - categorical_accuracy: 0.5349 - val_loss: 1.6224 - val_categorical_accuracy: 0.4156\n",
      "\n",
      "Epoch 00007: val_categorical_accuracy did not improve from 0.47500\n",
      "Epoch 8/25\n",
      "\n",
      "Epoch 00008: LearningRateScheduler setting learning rate to 0.00028182950060014905.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 1.2327 - categorical_accuracy: 0.5740 - val_loss: 1.6010 - val_categorical_accuracy: 0.4281\n",
      "\n",
      "Epoch 00008: val_categorical_accuracy did not improve from 0.47500\n",
      "Epoch 9/25\n",
      "\n",
      "Epoch 00009: LearningRateScheduler setting learning rate to 0.0002793251563668079.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 1.1299 - categorical_accuracy: 0.6149 - val_loss: 1.5876 - val_categorical_accuracy: 0.4547\n",
      "\n",
      "Epoch 00009: val_categorical_accuracy did not improve from 0.47500\n",
      "Epoch 10/25\n",
      "\n",
      "Epoch 00010: LearningRateScheduler setting learning rate to 0.00027684306580111226.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 1.0538 - categorical_accuracy: 0.6455 - val_loss: 1.6387 - val_categorical_accuracy: 0.4359\n",
      "\n",
      "Epoch 00010: val_categorical_accuracy did not improve from 0.47500\n",
      "Epoch 11/25\n",
      "\n",
      "Epoch 00011: LearningRateScheduler setting learning rate to 0.0002743830311563958.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 0.9607 - categorical_accuracy: 0.6847 - val_loss: 1.6810 - val_categorical_accuracy: 0.4422\n",
      "\n",
      "Epoch 00011: val_categorical_accuracy did not improve from 0.47500\n",
      "Epoch 12/25\n",
      "\n",
      "Epoch 00012: LearningRateScheduler setting learning rate to 0.00027194485644317407.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 0.8818 - categorical_accuracy: 0.7151 - val_loss: 1.7062 - val_categorical_accuracy: 0.4422\n",
      "\n",
      "Epoch 00012: val_categorical_accuracy did not improve from 0.47500\n",
      "Epoch 13/25\n",
      "\n",
      "Epoch 00013: LearningRateScheduler setting learning rate to 0.0002695283474135303.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 0.8098 - categorical_accuracy: 0.7399 - val_loss: 1.6943 - val_categorical_accuracy: 0.4563\n",
      "\n",
      "Epoch 00013: val_categorical_accuracy did not improve from 0.47500\n",
      "Epoch 14/25\n",
      "\n",
      "Epoch 00014: LearningRateScheduler setting learning rate to 0.0002671333115456397.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 0.7435 - categorical_accuracy: 0.7755 - val_loss: 1.7289 - val_categorical_accuracy: 0.4547\n",
      "\n",
      "Epoch 00014: val_categorical_accuracy did not improve from 0.47500\n",
      "Epoch 15/25\n",
      "\n",
      "Epoch 00015: LearningRateScheduler setting learning rate to 0.0002647595580284314.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 0.6794 - categorical_accuracy: 0.7936 - val_loss: 1.7163 - val_categorical_accuracy: 0.4922\n",
      "\n",
      "Epoch 00015: val_categorical_accuracy improved from 0.47500 to 0.49219, saving model to ./temp/ckpt\n",
      "Epoch 16/25\n",
      "\n",
      "Epoch 00016: LearningRateScheduler setting learning rate to 0.00026240689774638675.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 0.6298 - categorical_accuracy: 0.8177 - val_loss: 1.7797 - val_categorical_accuracy: 0.4703\n",
      "\n",
      "Epoch 00016: val_categorical_accuracy did not improve from 0.49219\n",
      "Epoch 17/25\n",
      "\n",
      "Epoch 00017: LearningRateScheduler setting learning rate to 0.00026007514326447225.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 0.5801 - categorical_accuracy: 0.8333 - val_loss: 1.8209 - val_categorical_accuracy: 0.4844\n",
      "\n",
      "Epoch 00017: val_categorical_accuracy did not improve from 0.49219\n",
      "Epoch 18/25\n",
      "\n",
      "Epoch 00018: LearningRateScheduler setting learning rate to 0.00025776410881320726.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 0.5228 - categorical_accuracy: 0.8458 - val_loss: 1.8532 - val_categorical_accuracy: 0.4781\n",
      "\n",
      "Epoch 00018: val_categorical_accuracy did not improve from 0.49219\n",
      "Epoch 19/25\n",
      "\n",
      "Epoch 00019: LearningRateScheduler setting learning rate to 0.0002554736102738633.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 0.4949 - categorical_accuracy: 0.8576 - val_loss: 1.9062 - val_categorical_accuracy: 0.4844\n",
      "\n",
      "Epoch 00019: val_categorical_accuracy did not improve from 0.49219\n",
      "Epoch 00019: early stopping\n",
      "models num: 2\n",
      "Train on 5760 samples, validate on 640 samples\n",
      "Epoch 1/25\n",
      "\n",
      "Epoch 00001: LearningRateScheduler setting learning rate to 0.0003.\n",
      "5760/5760 [==============================] - 17s 3ms/step - loss: 2.2871 - categorical_accuracy: 0.1694 - val_loss: 2.2643 - val_categorical_accuracy: 0.1781\n",
      "\n",
      "Epoch 00001: val_categorical_accuracy did not improve from 0.49219\n",
      "Epoch 2/25\n",
      "\n",
      "Epoch 00002: LearningRateScheduler setting learning rate to 0.0002973341922389158.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 2.2212 - categorical_accuracy: 0.1854 - val_loss: 2.1641 - val_categorical_accuracy: 0.2484\n",
      "\n",
      "Epoch 00002: val_categorical_accuracy did not improve from 0.49219\n",
      "Epoch 3/25\n",
      "\n",
      "Epoch 00003: LearningRateScheduler setting learning rate to 0.0002946920729145618.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 2.0455 - categorical_accuracy: 0.3085 - val_loss: 1.9200 - val_categorical_accuracy: 0.3625\n",
      "\n",
      "Epoch 00003: val_categorical_accuracy did not improve from 0.49219\n",
      "Epoch 4/25\n",
      "\n",
      "Epoch 00004: LearningRateScheduler setting learning rate to 0.0002920734315308764.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 1.7933 - categorical_accuracy: 0.3780 - val_loss: 1.7467 - val_categorical_accuracy: 0.3859\n",
      "\n",
      "Epoch 00004: val_categorical_accuracy did not improve from 0.49219\n",
      "Epoch 5/25\n",
      "\n",
      "Epoch 00005: LearningRateScheduler setting learning rate to 0.00028947805946227145.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 1.6228 - categorical_accuracy: 0.4295 - val_loss: 1.6576 - val_categorical_accuracy: 0.4219\n",
      "\n",
      "Epoch 00005: val_categorical_accuracy did not improve from 0.49219\n",
      "Epoch 6/25\n",
      "\n",
      "Epoch 00006: LearningRateScheduler setting learning rate to 0.0002869057499370111.\n",
      "5760/5760 [==============================] - 10s 2ms/step - loss: 1.4912 - categorical_accuracy: 0.4819 - val_loss: 1.6083 - val_categorical_accuracy: 0.4422\n",
      "\n",
      "Epoch 00006: val_categorical_accuracy did not improve from 0.49219\n",
      "Epoch 7/25\n",
      "\n",
      "Epoch 00007: LearningRateScheduler setting learning rate to 0.00028435629802073855.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 1.3726 - categorical_accuracy: 0.5210 - val_loss: 1.5870 - val_categorical_accuracy: 0.4406\n",
      "\n",
      "Epoch 00007: val_categorical_accuracy did not improve from 0.49219\n",
      "Epoch 8/25\n",
      "\n",
      "Epoch 00008: LearningRateScheduler setting learning rate to 0.00028182950060014905.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 1.2615 - categorical_accuracy: 0.5497 - val_loss: 1.5621 - val_categorical_accuracy: 0.4500\n",
      "\n",
      "Epoch 00008: val_categorical_accuracy did not improve from 0.49219\n",
      "Epoch 9/25\n",
      "\n",
      "Epoch 00009: LearningRateScheduler setting learning rate to 0.0002793251563668079.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 1.1602 - categorical_accuracy: 0.5894 - val_loss: 1.5720 - val_categorical_accuracy: 0.4641\n",
      "\n",
      "Epoch 00009: val_categorical_accuracy did not improve from 0.49219\n",
      "Epoch 10/25\n",
      "\n",
      "Epoch 00010: LearningRateScheduler setting learning rate to 0.00027684306580111226.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 1.0692 - categorical_accuracy: 0.6245 - val_loss: 1.5941 - val_categorical_accuracy: 0.4734\n",
      "\n",
      "Epoch 00010: val_categorical_accuracy did not improve from 0.49219\n",
      "Epoch 11/25\n",
      "\n",
      "Epoch 00011: LearningRateScheduler setting learning rate to 0.0002743830311563958.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 0.9895 - categorical_accuracy: 0.6578 - val_loss: 1.6773 - val_categorical_accuracy: 0.4672\n",
      "\n",
      "Epoch 00011: val_categorical_accuracy did not improve from 0.49219\n",
      "Epoch 12/25\n",
      "\n",
      "Epoch 00012: LearningRateScheduler setting learning rate to 0.00027194485644317407.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 0.9123 - categorical_accuracy: 0.6938 - val_loss: 1.6452 - val_categorical_accuracy: 0.4719\n",
      "\n",
      "Epoch 00012: val_categorical_accuracy did not improve from 0.49219\n",
      "Epoch 13/25\n",
      "\n",
      "Epoch 00013: LearningRateScheduler setting learning rate to 0.0002695283474135303.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5760/5760 [==============================] - 9s 2ms/step - loss: 0.8295 - categorical_accuracy: 0.7231 - val_loss: 1.7515 - val_categorical_accuracy: 0.4734\n",
      "\n",
      "Epoch 00013: val_categorical_accuracy did not improve from 0.49219\n",
      "Epoch 14/25\n",
      "\n",
      "Epoch 00014: LearningRateScheduler setting learning rate to 0.0002671333115456397.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 0.7889 - categorical_accuracy: 0.7425 - val_loss: 1.7615 - val_categorical_accuracy: 0.4688\n",
      "\n",
      "Epoch 00014: val_categorical_accuracy did not improve from 0.49219\n",
      "Epoch 15/25\n",
      "\n",
      "Epoch 00015: LearningRateScheduler setting learning rate to 0.0002647595580284314.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 0.7147 - categorical_accuracy: 0.7776 - val_loss: 1.8176 - val_categorical_accuracy: 0.4703\n",
      "\n",
      "Epoch 00015: val_categorical_accuracy did not improve from 0.49219\n",
      "Epoch 16/25\n",
      "\n",
      "Epoch 00016: LearningRateScheduler setting learning rate to 0.00026240689774638675.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 0.6599 - categorical_accuracy: 0.7960 - val_loss: 1.8390 - val_categorical_accuracy: 0.4781\n",
      "\n",
      "Epoch 00016: val_categorical_accuracy did not improve from 0.49219\n",
      "Epoch 17/25\n",
      "\n",
      "Epoch 00017: LearningRateScheduler setting learning rate to 0.00026007514326447225.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 0.6284 - categorical_accuracy: 0.8052 - val_loss: 1.9361 - val_categorical_accuracy: 0.4625\n",
      "\n",
      "Epoch 00017: val_categorical_accuracy did not improve from 0.49219\n",
      "Epoch 18/25\n",
      "\n",
      "Epoch 00018: LearningRateScheduler setting learning rate to 0.00025776410881320726.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 0.5742 - categorical_accuracy: 0.8274 - val_loss: 1.9790 - val_categorical_accuracy: 0.4781\n",
      "\n",
      "Epoch 00018: val_categorical_accuracy did not improve from 0.49219\n",
      "Epoch 00018: early stopping\n",
      "models num: 3\n",
      "Train on 5760 samples, validate on 640 samples\n",
      "Epoch 1/25\n",
      "\n",
      "Epoch 00001: LearningRateScheduler setting learning rate to 0.0003.\n",
      "5760/5760 [==============================] - 17s 3ms/step - loss: 2.2833 - categorical_accuracy: 0.1604 - val_loss: 2.2611 - val_categorical_accuracy: 0.1594\n",
      "\n",
      "Epoch 00001: val_categorical_accuracy did not improve from 0.49219\n",
      "Epoch 2/25\n",
      "\n",
      "Epoch 00002: LearningRateScheduler setting learning rate to 0.0002973341922389158.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 2.2066 - categorical_accuracy: 0.1922 - val_loss: 2.1636 - val_categorical_accuracy: 0.2469\n",
      "\n",
      "Epoch 00002: val_categorical_accuracy did not improve from 0.49219\n",
      "Epoch 3/25\n",
      "\n",
      "Epoch 00003: LearningRateScheduler setting learning rate to 0.0002946920729145618.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 2.0167 - categorical_accuracy: 0.3139 - val_loss: 1.9379 - val_categorical_accuracy: 0.3594\n",
      "\n",
      "Epoch 00003: val_categorical_accuracy did not improve from 0.49219\n",
      "Epoch 4/25\n",
      "\n",
      "Epoch 00004: LearningRateScheduler setting learning rate to 0.0002920734315308764.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 1.7824 - categorical_accuracy: 0.3818 - val_loss: 1.8136 - val_categorical_accuracy: 0.3594\n",
      "\n",
      "Epoch 00004: val_categorical_accuracy did not improve from 0.49219\n",
      "Epoch 5/25\n",
      "\n",
      "Epoch 00005: LearningRateScheduler setting learning rate to 0.00028947805946227145.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 1.6324 - categorical_accuracy: 0.4214 - val_loss: 1.7335 - val_categorical_accuracy: 0.4031\n",
      "\n",
      "Epoch 00005: val_categorical_accuracy did not improve from 0.49219\n",
      "Epoch 6/25\n",
      "\n",
      "Epoch 00006: LearningRateScheduler setting learning rate to 0.0002869057499370111.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 1.5126 - categorical_accuracy: 0.4668 - val_loss: 1.6785 - val_categorical_accuracy: 0.4156\n",
      "\n",
      "Epoch 00006: val_categorical_accuracy did not improve from 0.49219\n",
      "Epoch 7/25\n",
      "\n",
      "Epoch 00007: LearningRateScheduler setting learning rate to 0.00028435629802073855.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 1.4022 - categorical_accuracy: 0.5128 - val_loss: 1.6481 - val_categorical_accuracy: 0.4500\n",
      "\n",
      "Epoch 00007: val_categorical_accuracy did not improve from 0.49219\n",
      "Epoch 8/25\n",
      "\n",
      "Epoch 00008: LearningRateScheduler setting learning rate to 0.00028182950060014905.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 1.3049 - categorical_accuracy: 0.5530 - val_loss: 1.6567 - val_categorical_accuracy: 0.4516\n",
      "\n",
      "Epoch 00008: val_categorical_accuracy did not improve from 0.49219\n",
      "Epoch 9/25\n",
      "\n",
      "Epoch 00009: LearningRateScheduler setting learning rate to 0.0002793251563668079.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 1.2035 - categorical_accuracy: 0.5903 - val_loss: 1.6453 - val_categorical_accuracy: 0.4625\n",
      "\n",
      "Epoch 00009: val_categorical_accuracy did not improve from 0.49219\n",
      "Epoch 10/25\n",
      "\n",
      "Epoch 00010: LearningRateScheduler setting learning rate to 0.00027684306580111226.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 1.1081 - categorical_accuracy: 0.6314 - val_loss: 1.6276 - val_categorical_accuracy: 0.4672\n",
      "\n",
      "Epoch 00010: val_categorical_accuracy did not improve from 0.49219\n",
      "Epoch 11/25\n",
      "\n",
      "Epoch 00011: LearningRateScheduler setting learning rate to 0.0002743830311563958.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 1.0179 - categorical_accuracy: 0.6679 - val_loss: 1.6367 - val_categorical_accuracy: 0.4688\n",
      "\n",
      "Epoch 00011: val_categorical_accuracy did not improve from 0.49219\n",
      "Epoch 12/25\n",
      "\n",
      "Epoch 00012: LearningRateScheduler setting learning rate to 0.00027194485644317407.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 0.9383 - categorical_accuracy: 0.6976 - val_loss: 1.6699 - val_categorical_accuracy: 0.4703\n",
      "\n",
      "Epoch 00012: val_categorical_accuracy did not improve from 0.49219\n",
      "Epoch 13/25\n",
      "\n",
      "Epoch 00013: LearningRateScheduler setting learning rate to 0.0002695283474135303.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 0.8513 - categorical_accuracy: 0.7323 - val_loss: 1.6975 - val_categorical_accuracy: 0.4859\n",
      "\n",
      "Epoch 00013: val_categorical_accuracy did not improve from 0.49219\n",
      "Epoch 14/25\n",
      "\n",
      "Epoch 00014: LearningRateScheduler setting learning rate to 0.0002671333115456397.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 0.7941 - categorical_accuracy: 0.7484 - val_loss: 1.7191 - val_categorical_accuracy: 0.4859\n",
      "\n",
      "Epoch 00014: val_categorical_accuracy did not improve from 0.49219\n",
      "Epoch 15/25\n",
      "\n",
      "Epoch 00015: LearningRateScheduler setting learning rate to 0.0002647595580284314.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 0.7388 - categorical_accuracy: 0.7672 - val_loss: 1.7687 - val_categorical_accuracy: 0.4953\n",
      "\n",
      "Epoch 00015: val_categorical_accuracy improved from 0.49219 to 0.49531, saving model to ./temp/ckpt\n",
      "Epoch 16/25\n",
      "\n",
      "Epoch 00016: LearningRateScheduler setting learning rate to 0.00026240689774638675.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 0.6823 - categorical_accuracy: 0.7908 - val_loss: 1.7602 - val_categorical_accuracy: 0.5109\n",
      "\n",
      "Epoch 00016: val_categorical_accuracy improved from 0.49531 to 0.51094, saving model to ./temp/ckpt\n",
      "Epoch 17/25\n",
      "\n",
      "Epoch 00017: LearningRateScheduler setting learning rate to 0.00026007514326447225.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 0.6274 - categorical_accuracy: 0.8026 - val_loss: 1.8179 - val_categorical_accuracy: 0.5141\n",
      "\n",
      "Epoch 00017: val_categorical_accuracy improved from 0.51094 to 0.51406, saving model to ./temp/ckpt\n",
      "Epoch 18/25\n",
      "\n",
      "Epoch 00018: LearningRateScheduler setting learning rate to 0.00025776410881320726.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 0.5962 - categorical_accuracy: 0.8222 - val_loss: 1.8088 - val_categorical_accuracy: 0.5047\n",
      "\n",
      "Epoch 00018: val_categorical_accuracy did not improve from 0.51406\n",
      "Epoch 19/25\n",
      "\n",
      "Epoch 00019: LearningRateScheduler setting learning rate to 0.0002554736102738633.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 0.5571 - categorical_accuracy: 0.8372 - val_loss: 1.8457 - val_categorical_accuracy: 0.5188\n",
      "\n",
      "Epoch 00019: val_categorical_accuracy improved from 0.51406 to 0.51875, saving model to ./temp/ckpt\n",
      "Epoch 20/25\n",
      "\n",
      "Epoch 00020: LearningRateScheduler setting learning rate to 0.00025320346516379574.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5760/5760 [==============================] - 9s 2ms/step - loss: 0.5070 - categorical_accuracy: 0.8464 - val_loss: 1.8870 - val_categorical_accuracy: 0.5219\n",
      "\n",
      "Epoch 00020: val_categorical_accuracy improved from 0.51875 to 0.52188, saving model to ./temp/ckpt\n",
      "Epoch 00020: early stopping\n",
      "models num: 4\n",
      "Train on 5760 samples, validate on 640 samples\n",
      "Epoch 1/25\n",
      "\n",
      "Epoch 00001: LearningRateScheduler setting learning rate to 0.0003.\n",
      "5760/5760 [==============================] - 17s 3ms/step - loss: 2.2846 - categorical_accuracy: 0.1582 - val_loss: 2.2589 - val_categorical_accuracy: 0.1562\n",
      "\n",
      "Epoch 00001: val_categorical_accuracy did not improve from 0.52188\n",
      "Epoch 2/25\n",
      "\n",
      "Epoch 00002: LearningRateScheduler setting learning rate to 0.0002973341922389158.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 2.2200 - categorical_accuracy: 0.1752 - val_loss: 2.1839 - val_categorical_accuracy: 0.2000\n",
      "\n",
      "Epoch 00002: val_categorical_accuracy did not improve from 0.52188\n",
      "Epoch 3/25\n",
      "\n",
      "Epoch 00003: LearningRateScheduler setting learning rate to 0.0002946920729145618.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 2.0567 - categorical_accuracy: 0.3069 - val_loss: 1.9573 - val_categorical_accuracy: 0.3422\n",
      "\n",
      "Epoch 00003: val_categorical_accuracy did not improve from 0.52188\n",
      "Epoch 4/25\n",
      "\n",
      "Epoch 00004: LearningRateScheduler setting learning rate to 0.0002920734315308764.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 1.8076 - categorical_accuracy: 0.3753 - val_loss: 1.7828 - val_categorical_accuracy: 0.3766\n",
      "\n",
      "Epoch 00004: val_categorical_accuracy did not improve from 0.52188\n",
      "Epoch 5/25\n",
      "\n",
      "Epoch 00005: LearningRateScheduler setting learning rate to 0.00028947805946227145.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 1.6357 - categorical_accuracy: 0.4377 - val_loss: 1.6921 - val_categorical_accuracy: 0.4031\n",
      "\n",
      "Epoch 00005: val_categorical_accuracy did not improve from 0.52188\n",
      "Epoch 6/25\n",
      "\n",
      "Epoch 00006: LearningRateScheduler setting learning rate to 0.0002869057499370111.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 1.4939 - categorical_accuracy: 0.4795 - val_loss: 1.6164 - val_categorical_accuracy: 0.4172\n",
      "\n",
      "Epoch 00006: val_categorical_accuracy did not improve from 0.52188\n",
      "Epoch 7/25\n",
      "\n",
      "Epoch 00007: LearningRateScheduler setting learning rate to 0.00028435629802073855.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 1.3622 - categorical_accuracy: 0.5283 - val_loss: 1.5812 - val_categorical_accuracy: 0.4359\n",
      "\n",
      "Epoch 00007: val_categorical_accuracy did not improve from 0.52188\n",
      "Epoch 8/25\n",
      "\n",
      "Epoch 00008: LearningRateScheduler setting learning rate to 0.00028182950060014905.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 1.2475 - categorical_accuracy: 0.5703 - val_loss: 1.5442 - val_categorical_accuracy: 0.4594\n",
      "\n",
      "Epoch 00008: val_categorical_accuracy did not improve from 0.52188\n",
      "Epoch 9/25\n",
      "\n",
      "Epoch 00009: LearningRateScheduler setting learning rate to 0.0002793251563668079.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 1.1264 - categorical_accuracy: 0.6210 - val_loss: 1.5503 - val_categorical_accuracy: 0.4594\n",
      "\n",
      "Epoch 00009: val_categorical_accuracy did not improve from 0.52188\n",
      "Epoch 10/25\n",
      "\n",
      "Epoch 00010: LearningRateScheduler setting learning rate to 0.00027684306580111226.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 1.0257 - categorical_accuracy: 0.6597 - val_loss: 1.5456 - val_categorical_accuracy: 0.4828\n",
      "\n",
      "Epoch 00010: val_categorical_accuracy did not improve from 0.52188\n",
      "Epoch 11/25\n",
      "\n",
      "Epoch 00011: LearningRateScheduler setting learning rate to 0.0002743830311563958.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 0.9310 - categorical_accuracy: 0.6967 - val_loss: 1.5464 - val_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00011: val_categorical_accuracy did not improve from 0.52188\n",
      "Epoch 12/25\n",
      "\n",
      "Epoch 00012: LearningRateScheduler setting learning rate to 0.00027194485644317407.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 0.8417 - categorical_accuracy: 0.7316 - val_loss: 1.5896 - val_categorical_accuracy: 0.5031\n",
      "\n",
      "Epoch 00012: val_categorical_accuracy did not improve from 0.52188\n",
      "Epoch 13/25\n",
      "\n",
      "Epoch 00013: LearningRateScheduler setting learning rate to 0.0002695283474135303.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 0.7685 - categorical_accuracy: 0.7594 - val_loss: 1.6219 - val_categorical_accuracy: 0.5125\n",
      "\n",
      "Epoch 00013: val_categorical_accuracy did not improve from 0.52188\n",
      "Epoch 14/25\n",
      "\n",
      "Epoch 00014: LearningRateScheduler setting learning rate to 0.0002671333115456397.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 0.7004 - categorical_accuracy: 0.7901 - val_loss: 1.6674 - val_categorical_accuracy: 0.5016\n",
      "\n",
      "Epoch 00014: val_categorical_accuracy did not improve from 0.52188\n",
      "Epoch 15/25\n",
      "\n",
      "Epoch 00015: LearningRateScheduler setting learning rate to 0.0002647595580284314.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 0.6373 - categorical_accuracy: 0.8045 - val_loss: 1.7045 - val_categorical_accuracy: 0.5125\n",
      "\n",
      "Epoch 00015: val_categorical_accuracy did not improve from 0.52188\n",
      "Epoch 16/25\n",
      "\n",
      "Epoch 00016: LearningRateScheduler setting learning rate to 0.00026240689774638675.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 0.5973 - categorical_accuracy: 0.8191 - val_loss: 1.7257 - val_categorical_accuracy: 0.5078\n",
      "\n",
      "Epoch 00016: val_categorical_accuracy did not improve from 0.52188\n",
      "Epoch 17/25\n",
      "\n",
      "Epoch 00017: LearningRateScheduler setting learning rate to 0.00026007514326447225.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 0.5497 - categorical_accuracy: 0.8285 - val_loss: 1.7839 - val_categorical_accuracy: 0.5234\n",
      "\n",
      "Epoch 00017: val_categorical_accuracy improved from 0.52188 to 0.52344, saving model to ./temp/ckpt\n",
      "Epoch 18/25\n",
      "\n",
      "Epoch 00018: LearningRateScheduler setting learning rate to 0.00025776410881320726.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 0.4994 - categorical_accuracy: 0.8524 - val_loss: 1.7917 - val_categorical_accuracy: 0.5266\n",
      "\n",
      "Epoch 00018: val_categorical_accuracy improved from 0.52344 to 0.52656, saving model to ./temp/ckpt\n",
      "Epoch 00018: early stopping\n",
      "models num: 5\n",
      "Train on 5760 samples, validate on 640 samples\n",
      "Epoch 1/25\n",
      "\n",
      "Epoch 00001: LearningRateScheduler setting learning rate to 0.0003.\n",
      "5760/5760 [==============================] - 17s 3ms/step - loss: 2.2861 - categorical_accuracy: 0.1533 - val_loss: 2.2622 - val_categorical_accuracy: 0.1531\n",
      "\n",
      "Epoch 00001: val_categorical_accuracy did not improve from 0.52656\n",
      "Epoch 2/25\n",
      "\n",
      "Epoch 00002: LearningRateScheduler setting learning rate to 0.0002973341922389158.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 2.2163 - categorical_accuracy: 0.1792 - val_loss: 2.1716 - val_categorical_accuracy: 0.2391\n",
      "\n",
      "Epoch 00002: val_categorical_accuracy did not improve from 0.52656\n",
      "Epoch 3/25\n",
      "\n",
      "Epoch 00003: LearningRateScheduler setting learning rate to 0.0002946920729145618.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 2.0699 - categorical_accuracy: 0.2852 - val_loss: 1.9445 - val_categorical_accuracy: 0.3469\n",
      "\n",
      "Epoch 00003: val_categorical_accuracy did not improve from 0.52656\n",
      "Epoch 4/25\n",
      "\n",
      "Epoch 00004: LearningRateScheduler setting learning rate to 0.0002920734315308764.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 1.8176 - categorical_accuracy: 0.3734 - val_loss: 1.7585 - val_categorical_accuracy: 0.4062\n",
      "\n",
      "Epoch 00004: val_categorical_accuracy did not improve from 0.52656\n",
      "Epoch 5/25\n",
      "\n",
      "Epoch 00005: LearningRateScheduler setting learning rate to 0.00028947805946227145.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 1.6338 - categorical_accuracy: 0.4424 - val_loss: 1.6457 - val_categorical_accuracy: 0.4266\n",
      "\n",
      "Epoch 00005: val_categorical_accuracy did not improve from 0.52656\n",
      "Epoch 6/25\n",
      "\n",
      "Epoch 00006: LearningRateScheduler setting learning rate to 0.0002869057499370111.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 1.4857 - categorical_accuracy: 0.4872 - val_loss: 1.5991 - val_categorical_accuracy: 0.4328\n",
      "\n",
      "Epoch 00006: val_categorical_accuracy did not improve from 0.52656\n",
      "Epoch 7/25\n",
      "\n",
      "Epoch 00007: LearningRateScheduler setting learning rate to 0.00028435629802073855.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5760/5760 [==============================] - 9s 2ms/step - loss: 1.3458 - categorical_accuracy: 0.5335 - val_loss: 1.5544 - val_categorical_accuracy: 0.4516\n",
      "\n",
      "Epoch 00007: val_categorical_accuracy did not improve from 0.52656\n",
      "Epoch 8/25\n",
      "\n",
      "Epoch 00008: LearningRateScheduler setting learning rate to 0.00028182950060014905.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 1.2381 - categorical_accuracy: 0.5701 - val_loss: 1.5686 - val_categorical_accuracy: 0.4734\n",
      "\n",
      "Epoch 00008: val_categorical_accuracy did not improve from 0.52656\n",
      "Epoch 9/25\n",
      "\n",
      "Epoch 00009: LearningRateScheduler setting learning rate to 0.0002793251563668079.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 1.1322 - categorical_accuracy: 0.6104 - val_loss: 1.5580 - val_categorical_accuracy: 0.4672\n",
      "\n",
      "Epoch 00009: val_categorical_accuracy did not improve from 0.52656\n",
      "Epoch 10/25\n",
      "\n",
      "Epoch 00010: LearningRateScheduler setting learning rate to 0.00027684306580111226.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 1.0367 - categorical_accuracy: 0.6448 - val_loss: 1.5760 - val_categorical_accuracy: 0.4703\n",
      "\n",
      "Epoch 00010: val_categorical_accuracy did not improve from 0.52656\n",
      "Epoch 11/25\n",
      "\n",
      "Epoch 00011: LearningRateScheduler setting learning rate to 0.0002743830311563958.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 0.9634 - categorical_accuracy: 0.6727 - val_loss: 1.5935 - val_categorical_accuracy: 0.4844\n",
      "\n",
      "Epoch 00011: val_categorical_accuracy did not improve from 0.52656\n",
      "Epoch 12/25\n",
      "\n",
      "Epoch 00012: LearningRateScheduler setting learning rate to 0.00027194485644317407.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 0.8958 - categorical_accuracy: 0.6957 - val_loss: 1.6092 - val_categorical_accuracy: 0.4859\n",
      "\n",
      "Epoch 00012: val_categorical_accuracy did not improve from 0.52656\n",
      "Epoch 13/25\n",
      "\n",
      "Epoch 00013: LearningRateScheduler setting learning rate to 0.0002695283474135303.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 0.8190 - categorical_accuracy: 0.7276 - val_loss: 1.6195 - val_categorical_accuracy: 0.4953\n",
      "\n",
      "Epoch 00013: val_categorical_accuracy did not improve from 0.52656\n",
      "Epoch 14/25\n",
      "\n",
      "Epoch 00014: LearningRateScheduler setting learning rate to 0.0002671333115456397.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 0.7569 - categorical_accuracy: 0.7616 - val_loss: 1.6263 - val_categorical_accuracy: 0.4812\n",
      "\n",
      "Epoch 00014: val_categorical_accuracy did not improve from 0.52656\n",
      "Epoch 15/25\n",
      "\n",
      "Epoch 00015: LearningRateScheduler setting learning rate to 0.0002647595580284314.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 0.6918 - categorical_accuracy: 0.7762 - val_loss: 1.7090 - val_categorical_accuracy: 0.4859\n",
      "\n",
      "Epoch 00015: val_categorical_accuracy did not improve from 0.52656\n",
      "Epoch 16/25\n",
      "\n",
      "Epoch 00016: LearningRateScheduler setting learning rate to 0.00026240689774638675.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 0.6522 - categorical_accuracy: 0.7932 - val_loss: 1.6937 - val_categorical_accuracy: 0.5016\n",
      "\n",
      "Epoch 00016: val_categorical_accuracy did not improve from 0.52656\n",
      "Epoch 17/25\n",
      "\n",
      "Epoch 00017: LearningRateScheduler setting learning rate to 0.00026007514326447225.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 0.6112 - categorical_accuracy: 0.8132 - val_loss: 1.7275 - val_categorical_accuracy: 0.5109\n",
      "\n",
      "Epoch 00017: val_categorical_accuracy did not improve from 0.52656\n",
      "Epoch 00017: early stopping\n",
      "models num: 6\n",
      "Train on 5760 samples, validate on 640 samples\n",
      "Epoch 1/25\n",
      "\n",
      "Epoch 00001: LearningRateScheduler setting learning rate to 0.0003.\n",
      "5760/5760 [==============================] - 17s 3ms/step - loss: 2.2843 - categorical_accuracy: 0.1628 - val_loss: 2.2646 - val_categorical_accuracy: 0.1375\n",
      "\n",
      "Epoch 00001: val_categorical_accuracy did not improve from 0.52656\n",
      "Epoch 2/25\n",
      "\n",
      "Epoch 00002: LearningRateScheduler setting learning rate to 0.0002973341922389158.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 2.2126 - categorical_accuracy: 0.1797 - val_loss: 2.1928 - val_categorical_accuracy: 0.1734\n",
      "\n",
      "Epoch 00002: val_categorical_accuracy did not improve from 0.52656\n",
      "Epoch 3/25\n",
      "\n",
      "Epoch 00003: LearningRateScheduler setting learning rate to 0.0002946920729145618.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 2.0546 - categorical_accuracy: 0.2917 - val_loss: 1.9948 - val_categorical_accuracy: 0.3219\n",
      "\n",
      "Epoch 00003: val_categorical_accuracy did not improve from 0.52656\n",
      "Epoch 4/25\n",
      "\n",
      "Epoch 00004: LearningRateScheduler setting learning rate to 0.0002920734315308764.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 1.8200 - categorical_accuracy: 0.3785 - val_loss: 1.8264 - val_categorical_accuracy: 0.3609\n",
      "\n",
      "Epoch 00004: val_categorical_accuracy did not improve from 0.52656\n",
      "Epoch 5/25\n",
      "\n",
      "Epoch 00005: LearningRateScheduler setting learning rate to 0.00028947805946227145.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 1.6468 - categorical_accuracy: 0.4344 - val_loss: 1.7068 - val_categorical_accuracy: 0.3969\n",
      "\n",
      "Epoch 00005: val_categorical_accuracy did not improve from 0.52656\n",
      "Epoch 6/25\n",
      "\n",
      "Epoch 00006: LearningRateScheduler setting learning rate to 0.0002869057499370111.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 1.4916 - categorical_accuracy: 0.4885 - val_loss: 1.6778 - val_categorical_accuracy: 0.4094\n",
      "\n",
      "Epoch 00006: val_categorical_accuracy did not improve from 0.52656\n",
      "Epoch 7/25\n",
      "\n",
      "Epoch 00007: LearningRateScheduler setting learning rate to 0.00028435629802073855.\n",
      "5760/5760 [==============================] - 10s 2ms/step - loss: 1.3599 - categorical_accuracy: 0.5352 - val_loss: 1.6359 - val_categorical_accuracy: 0.4328\n",
      "\n",
      "Epoch 00007: val_categorical_accuracy did not improve from 0.52656\n",
      "Epoch 8/25\n",
      "\n",
      "Epoch 00008: LearningRateScheduler setting learning rate to 0.00028182950060014905.\n",
      "5760/5760 [==============================] - 10s 2ms/step - loss: 1.2377 - categorical_accuracy: 0.5774 - val_loss: 1.6680 - val_categorical_accuracy: 0.4375\n",
      "\n",
      "Epoch 00008: val_categorical_accuracy did not improve from 0.52656\n",
      "Epoch 9/25\n",
      "\n",
      "Epoch 00009: LearningRateScheduler setting learning rate to 0.0002793251563668079.\n",
      "5760/5760 [==============================] - 10s 2ms/step - loss: 1.1476 - categorical_accuracy: 0.6106 - val_loss: 1.6612 - val_categorical_accuracy: 0.4375\n",
      "\n",
      "Epoch 00009: val_categorical_accuracy did not improve from 0.52656\n",
      "Epoch 10/25\n",
      "\n",
      "Epoch 00010: LearningRateScheduler setting learning rate to 0.00027684306580111226.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 1.0524 - categorical_accuracy: 0.6549 - val_loss: 1.7093 - val_categorical_accuracy: 0.4359\n",
      "\n",
      "Epoch 00010: val_categorical_accuracy did not improve from 0.52656\n",
      "Epoch 11/25\n",
      "\n",
      "Epoch 00011: LearningRateScheduler setting learning rate to 0.0002743830311563958.\n",
      "5760/5760 [==============================] - 10s 2ms/step - loss: 0.9674 - categorical_accuracy: 0.6887 - val_loss: 1.6965 - val_categorical_accuracy: 0.4500\n",
      "\n",
      "Epoch 00011: val_categorical_accuracy did not improve from 0.52656\n",
      "Epoch 12/25\n",
      "\n",
      "Epoch 00012: LearningRateScheduler setting learning rate to 0.00027194485644317407.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 0.8895 - categorical_accuracy: 0.7035 - val_loss: 1.7636 - val_categorical_accuracy: 0.4531\n",
      "\n",
      "Epoch 00012: val_categorical_accuracy did not improve from 0.52656\n",
      "Epoch 13/25\n",
      "\n",
      "Epoch 00013: LearningRateScheduler setting learning rate to 0.0002695283474135303.\n",
      "5760/5760 [==============================] - 10s 2ms/step - loss: 0.8187 - categorical_accuracy: 0.7373 - val_loss: 1.8369 - val_categorical_accuracy: 0.4547\n",
      "\n",
      "Epoch 00013: val_categorical_accuracy did not improve from 0.52656\n",
      "Epoch 14/25\n",
      "\n",
      "Epoch 00014: LearningRateScheduler setting learning rate to 0.0002671333115456397.\n",
      "5760/5760 [==============================] - 10s 2ms/step - loss: 0.7463 - categorical_accuracy: 0.7691 - val_loss: 1.8852 - val_categorical_accuracy: 0.4563\n",
      "\n",
      "Epoch 00014: val_categorical_accuracy did not improve from 0.52656\n",
      "Epoch 15/25\n",
      "\n",
      "Epoch 00015: LearningRateScheduler setting learning rate to 0.0002647595580284314.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5760/5760 [==============================] - 9s 2ms/step - loss: 0.6994 - categorical_accuracy: 0.7854 - val_loss: 1.9212 - val_categorical_accuracy: 0.4641\n",
      "\n",
      "Epoch 00015: val_categorical_accuracy did not improve from 0.52656\n",
      "Epoch 16/25\n",
      "\n",
      "Epoch 00016: LearningRateScheduler setting learning rate to 0.00026240689774638675.\n",
      "5760/5760 [==============================] - 10s 2ms/step - loss: 0.6494 - categorical_accuracy: 0.8014 - val_loss: 1.9818 - val_categorical_accuracy: 0.4672\n",
      "\n",
      "Epoch 00016: val_categorical_accuracy did not improve from 0.52656\n",
      "Epoch 17/25\n",
      "\n",
      "Epoch 00017: LearningRateScheduler setting learning rate to 0.00026007514326447225.\n",
      "5760/5760 [==============================] - 10s 2ms/step - loss: 0.6046 - categorical_accuracy: 0.8191 - val_loss: 1.9661 - val_categorical_accuracy: 0.4609\n",
      "\n",
      "Epoch 00017: val_categorical_accuracy did not improve from 0.52656\n",
      "Epoch 00017: early stopping\n",
      "models num: 7\n",
      "Train on 5760 samples, validate on 640 samples\n",
      "Epoch 1/25\n",
      "\n",
      "Epoch 00001: LearningRateScheduler setting learning rate to 0.0003.\n",
      "5760/5760 [==============================] - 18s 3ms/step - loss: 2.2869 - categorical_accuracy: 0.1526 - val_loss: 2.2521 - val_categorical_accuracy: 0.1719\n",
      "\n",
      "Epoch 00001: val_categorical_accuracy did not improve from 0.52656\n",
      "Epoch 2/25\n",
      "\n",
      "Epoch 00002: LearningRateScheduler setting learning rate to 0.0002973341922389158.\n",
      "5760/5760 [==============================] - 10s 2ms/step - loss: 2.2213 - categorical_accuracy: 0.1790 - val_loss: 2.1725 - val_categorical_accuracy: 0.2016\n",
      "\n",
      "Epoch 00002: val_categorical_accuracy did not improve from 0.52656\n",
      "Epoch 3/25\n",
      "\n",
      "Epoch 00003: LearningRateScheduler setting learning rate to 0.0002946920729145618.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 2.0647 - categorical_accuracy: 0.2814 - val_loss: 1.9974 - val_categorical_accuracy: 0.3187\n",
      "\n",
      "Epoch 00003: val_categorical_accuracy did not improve from 0.52656\n",
      "Epoch 4/25\n",
      "\n",
      "Epoch 00004: LearningRateScheduler setting learning rate to 0.0002920734315308764.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 1.8119 - categorical_accuracy: 0.3733 - val_loss: 1.8669 - val_categorical_accuracy: 0.3469\n",
      "\n",
      "Epoch 00004: val_categorical_accuracy did not improve from 0.52656\n",
      "Epoch 5/25\n",
      "\n",
      "Epoch 00005: LearningRateScheduler setting learning rate to 0.00028947805946227145.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 1.6211 - categorical_accuracy: 0.4286 - val_loss: 1.7970 - val_categorical_accuracy: 0.3812\n",
      "\n",
      "Epoch 00005: val_categorical_accuracy did not improve from 0.52656\n",
      "Epoch 6/25\n",
      "\n",
      "Epoch 00006: LearningRateScheduler setting learning rate to 0.0002869057499370111.\n",
      "5760/5760 [==============================] - 10s 2ms/step - loss: 1.4621 - categorical_accuracy: 0.4903 - val_loss: 1.7682 - val_categorical_accuracy: 0.3953\n",
      "\n",
      "Epoch 00006: val_categorical_accuracy did not improve from 0.52656\n",
      "Epoch 7/25\n",
      "\n",
      "Epoch 00007: LearningRateScheduler setting learning rate to 0.00028435629802073855.\n",
      "5760/5760 [==============================] - 10s 2ms/step - loss: 1.3236 - categorical_accuracy: 0.5377 - val_loss: 1.7425 - val_categorical_accuracy: 0.4125\n",
      "\n",
      "Epoch 00007: val_categorical_accuracy did not improve from 0.52656\n",
      "Epoch 8/25\n",
      "\n",
      "Epoch 00008: LearningRateScheduler setting learning rate to 0.00028182950060014905.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 1.2061 - categorical_accuracy: 0.5866 - val_loss: 1.7447 - val_categorical_accuracy: 0.4359\n",
      "\n",
      "Epoch 00008: val_categorical_accuracy did not improve from 0.52656\n",
      "Epoch 9/25\n",
      "\n",
      "Epoch 00009: LearningRateScheduler setting learning rate to 0.0002793251563668079.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 1.1057 - categorical_accuracy: 0.6293 - val_loss: 1.7471 - val_categorical_accuracy: 0.4406\n",
      "\n",
      "Epoch 00009: val_categorical_accuracy did not improve from 0.52656\n",
      "Epoch 10/25\n",
      "\n",
      "Epoch 00010: LearningRateScheduler setting learning rate to 0.00027684306580111226.\n",
      "5760/5760 [==============================] - 9s 2ms/step - loss: 1.0142 - categorical_accuracy: 0.6646 - val_loss: 1.7420 - val_categorical_accuracy: 0.4719\n",
      "\n",
      "Epoch 00010: val_categorical_accuracy did not improve from 0.52656\n",
      "Epoch 11/25\n",
      "\n",
      "Epoch 00011: LearningRateScheduler setting learning rate to 0.0002743830311563958.\n",
      "5760/5760 [==============================] - 10s 2ms/step - loss: 0.9286 - categorical_accuracy: 0.7078 - val_loss: 1.7841 - val_categorical_accuracy: 0.4609\n",
      "\n",
      "Epoch 00011: val_categorical_accuracy did not improve from 0.52656\n",
      "Epoch 12/25\n",
      "\n",
      "Epoch 00012: LearningRateScheduler setting learning rate to 0.00027194485644317407.\n",
      "5760/5760 [==============================] - 10s 2ms/step - loss: 0.8399 - categorical_accuracy: 0.7377 - val_loss: 1.8230 - val_categorical_accuracy: 0.4672\n",
      "\n",
      "Epoch 00012: val_categorical_accuracy did not improve from 0.52656\n",
      "Epoch 13/25\n",
      "\n",
      "Epoch 00013: LearningRateScheduler setting learning rate to 0.0002695283474135303.\n",
      "5760/5760 [==============================] - 10s 2ms/step - loss: 0.7696 - categorical_accuracy: 0.7644 - val_loss: 1.8353 - val_categorical_accuracy: 0.4609\n",
      "\n",
      "Epoch 00013: val_categorical_accuracy did not improve from 0.52656\n",
      "Epoch 14/25\n",
      "\n",
      "Epoch 00014: LearningRateScheduler setting learning rate to 0.0002671333115456397.\n",
      "5760/5760 [==============================] - 11s 2ms/step - loss: 0.7100 - categorical_accuracy: 0.7887 - val_loss: 1.9096 - val_categorical_accuracy: 0.4719\n",
      "\n",
      "Epoch 00014: val_categorical_accuracy did not improve from 0.52656\n",
      "Epoch 15/25\n",
      "\n",
      "Epoch 00015: LearningRateScheduler setting learning rate to 0.0002647595580284314.\n",
      "5760/5760 [==============================] - 11s 2ms/step - loss: 0.6527 - categorical_accuracy: 0.8052 - val_loss: 1.9207 - val_categorical_accuracy: 0.4781\n",
      "\n",
      "Epoch 00015: val_categorical_accuracy did not improve from 0.52656\n",
      "Epoch 16/25\n",
      "\n",
      "Epoch 00016: LearningRateScheduler setting learning rate to 0.00026240689774638675.\n",
      "5760/5760 [==============================] - 11s 2ms/step - loss: 0.6027 - categorical_accuracy: 0.8231 - val_loss: 1.9477 - val_categorical_accuracy: 0.4672\n",
      "\n",
      "Epoch 00016: val_categorical_accuracy did not improve from 0.52656\n",
      "Epoch 17/25\n",
      "\n",
      "Epoch 00017: LearningRateScheduler setting learning rate to 0.00026007514326447225.\n",
      "5760/5760 [==============================] - 12s 2ms/step - loss: 0.5585 - categorical_accuracy: 0.8347 - val_loss: 1.9971 - val_categorical_accuracy: 0.4703\n",
      "\n",
      "Epoch 00017: val_categorical_accuracy did not improve from 0.52656\n",
      "Epoch 18/25\n",
      "\n",
      "Epoch 00018: LearningRateScheduler setting learning rate to 0.00025776410881320726.\n",
      "5760/5760 [==============================] - 11s 2ms/step - loss: 0.5141 - categorical_accuracy: 0.8530 - val_loss: 2.1261 - val_categorical_accuracy: 0.4672\n",
      "\n",
      "Epoch 00018: val_categorical_accuracy did not improve from 0.52656\n",
      "Epoch 19/25\n",
      "\n",
      "Epoch 00019: LearningRateScheduler setting learning rate to 0.0002554736102738633.\n",
      "5760/5760 [==============================] - 12s 2ms/step - loss: 0.4854 - categorical_accuracy: 0.8589 - val_loss: 2.0932 - val_categorical_accuracy: 0.4719\n",
      "\n",
      "Epoch 00019: val_categorical_accuracy did not improve from 0.52656\n",
      "Epoch 20/25\n",
      "\n",
      "Epoch 00020: LearningRateScheduler setting learning rate to 0.00025320346516379574.\n",
      "5760/5760 [==============================] - 12s 2ms/step - loss: 0.4517 - categorical_accuracy: 0.8689 - val_loss: 2.1582 - val_categorical_accuracy: 0.4703\n",
      "\n",
      "Epoch 00020: val_categorical_accuracy did not improve from 0.52656\n",
      "Epoch 00020: early stopping\n",
      "models num: 8\n",
      "Train on 5760 samples, validate on 640 samples\n",
      "Epoch 1/25\n",
      "\n",
      "Epoch 00001: LearningRateScheduler setting learning rate to 0.0003.\n",
      "5760/5760 [==============================] - 20s 3ms/step - loss: 2.2853 - categorical_accuracy: 0.1517 - val_loss: 2.2569 - val_categorical_accuracy: 0.1844\n",
      "\n",
      "Epoch 00001: val_categorical_accuracy did not improve from 0.52656\n",
      "Epoch 2/25\n",
      "\n",
      "Epoch 00002: LearningRateScheduler setting learning rate to 0.0002973341922389158.\n",
      "5760/5760 [==============================] - 11s 2ms/step - loss: 2.2213 - categorical_accuracy: 0.1769 - val_loss: 2.1696 - val_categorical_accuracy: 0.2328\n",
      "\n",
      "Epoch 00002: val_categorical_accuracy did not improve from 0.52656\n",
      "Epoch 3/25\n",
      "\n",
      "Epoch 00003: LearningRateScheduler setting learning rate to 0.0002946920729145618.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5760/5760 [==============================] - 10s 2ms/step - loss: 2.0524 - categorical_accuracy: 0.3059 - val_loss: 1.9446 - val_categorical_accuracy: 0.3406\n",
      "\n",
      "Epoch 00003: val_categorical_accuracy did not improve from 0.52656\n",
      "Epoch 4/25\n",
      "\n",
      "Epoch 00004: LearningRateScheduler setting learning rate to 0.0002920734315308764.\n",
      "5760/5760 [==============================] - 10s 2ms/step - loss: 1.7981 - categorical_accuracy: 0.3898 - val_loss: 1.7879 - val_categorical_accuracy: 0.3828\n",
      "\n",
      "Epoch 00004: val_categorical_accuracy did not improve from 0.52656\n",
      "Epoch 5/25\n",
      "\n",
      "Epoch 00005: LearningRateScheduler setting learning rate to 0.00028947805946227145.\n",
      "5760/5760 [==============================] - 10s 2ms/step - loss: 1.6169 - categorical_accuracy: 0.4479 - val_loss: 1.6890 - val_categorical_accuracy: 0.4172\n",
      "\n",
      "Epoch 00005: val_categorical_accuracy did not improve from 0.52656\n",
      "Epoch 6/25\n",
      "\n",
      "Epoch 00006: LearningRateScheduler setting learning rate to 0.0002869057499370111.\n",
      "5760/5760 [==============================] - 11s 2ms/step - loss: 1.4564 - categorical_accuracy: 0.5033 - val_loss: 1.6357 - val_categorical_accuracy: 0.4391\n",
      "\n",
      "Epoch 00006: val_categorical_accuracy did not improve from 0.52656\n",
      "Epoch 7/25\n",
      "\n",
      "Epoch 00007: LearningRateScheduler setting learning rate to 0.00028435629802073855.\n",
      "5760/5760 [==============================] - 11s 2ms/step - loss: 1.3173 - categorical_accuracy: 0.5538 - val_loss: 1.5956 - val_categorical_accuracy: 0.4469\n",
      "\n",
      "Epoch 00007: val_categorical_accuracy did not improve from 0.52656\n",
      "Epoch 8/25\n",
      "\n",
      "Epoch 00008: LearningRateScheduler setting learning rate to 0.00028182950060014905.\n",
      "5760/5760 [==============================] - 10s 2ms/step - loss: 1.2108 - categorical_accuracy: 0.5991 - val_loss: 1.6311 - val_categorical_accuracy: 0.4484\n",
      "\n",
      "Epoch 00008: val_categorical_accuracy did not improve from 0.52656\n",
      "Epoch 9/25\n",
      "\n",
      "Epoch 00009: LearningRateScheduler setting learning rate to 0.0002793251563668079.\n",
      "5760/5760 [==============================] - 10s 2ms/step - loss: 1.1053 - categorical_accuracy: 0.6333 - val_loss: 1.6292 - val_categorical_accuracy: 0.4703\n",
      "\n",
      "Epoch 00009: val_categorical_accuracy did not improve from 0.52656\n",
      "Epoch 10/25\n",
      "\n",
      "Epoch 00010: LearningRateScheduler setting learning rate to 0.00027684306580111226.\n",
      "5760/5760 [==============================] - 10s 2ms/step - loss: 1.0145 - categorical_accuracy: 0.6618 - val_loss: 1.6813 - val_categorical_accuracy: 0.4578\n",
      "\n",
      "Epoch 00010: val_categorical_accuracy did not improve from 0.52656\n",
      "Epoch 11/25\n",
      "\n",
      "Epoch 00011: LearningRateScheduler setting learning rate to 0.0002743830311563958.\n",
      "5760/5760 [==============================] - 10s 2ms/step - loss: 0.9414 - categorical_accuracy: 0.6882 - val_loss: 1.6830 - val_categorical_accuracy: 0.4594\n",
      "\n",
      "Epoch 00011: val_categorical_accuracy did not improve from 0.52656\n",
      "Epoch 12/25\n",
      "\n",
      "Epoch 00012: LearningRateScheduler setting learning rate to 0.00027194485644317407.\n",
      "5760/5760 [==============================] - 10s 2ms/step - loss: 0.8666 - categorical_accuracy: 0.7210 - val_loss: 1.7390 - val_categorical_accuracy: 0.4516\n",
      "\n",
      "Epoch 00012: val_categorical_accuracy did not improve from 0.52656\n",
      "Epoch 13/25\n",
      "\n",
      "Epoch 00013: LearningRateScheduler setting learning rate to 0.0002695283474135303.\n",
      "5760/5760 [==============================] - 10s 2ms/step - loss: 0.8069 - categorical_accuracy: 0.7410 - val_loss: 1.7759 - val_categorical_accuracy: 0.4469\n",
      "\n",
      "Epoch 00013: val_categorical_accuracy did not improve from 0.52656\n",
      "Epoch 14/25\n",
      "\n",
      "Epoch 00014: LearningRateScheduler setting learning rate to 0.0002671333115456397.\n",
      "5760/5760 [==============================] - 11s 2ms/step - loss: 0.7396 - categorical_accuracy: 0.7658 - val_loss: 1.7908 - val_categorical_accuracy: 0.4500\n",
      "\n",
      "Epoch 00014: val_categorical_accuracy did not improve from 0.52656\n",
      "Epoch 15/25\n",
      "\n",
      "Epoch 00015: LearningRateScheduler setting learning rate to 0.0002647595580284314.\n",
      "5760/5760 [==============================] - 12s 2ms/step - loss: 0.7037 - categorical_accuracy: 0.7806 - val_loss: 1.8341 - val_categorical_accuracy: 0.4359\n",
      "\n",
      "Epoch 00015: val_categorical_accuracy did not improve from 0.52656\n",
      "Epoch 16/25\n",
      "\n",
      "Epoch 00016: LearningRateScheduler setting learning rate to 0.00026240689774638675.\n",
      "5760/5760 [==============================] - 10s 2ms/step - loss: 0.6554 - categorical_accuracy: 0.7990 - val_loss: 1.8798 - val_categorical_accuracy: 0.4500\n",
      "\n",
      "Epoch 00016: val_categorical_accuracy did not improve from 0.52656\n",
      "Epoch 17/25\n",
      "\n",
      "Epoch 00017: LearningRateScheduler setting learning rate to 0.00026007514326447225.\n",
      "5760/5760 [==============================] - 10s 2ms/step - loss: 0.5992 - categorical_accuracy: 0.8188 - val_loss: 1.9579 - val_categorical_accuracy: 0.4359\n",
      "\n",
      "Epoch 00017: val_categorical_accuracy did not improve from 0.52656\n",
      "Epoch 00017: early stopping\n",
      "models num: 9\n",
      "Train on 5760 samples, validate on 640 samples\n",
      "Epoch 1/25\n",
      "\n",
      "Epoch 00001: LearningRateScheduler setting learning rate to 0.0003.\n",
      "5760/5760 [==============================] - 20s 3ms/step - loss: 2.2816 - categorical_accuracy: 0.1566 - val_loss: 2.2453 - val_categorical_accuracy: 0.1672\n",
      "\n",
      "Epoch 00001: val_categorical_accuracy did not improve from 0.52656\n",
      "Epoch 2/25\n",
      "\n",
      "Epoch 00002: LearningRateScheduler setting learning rate to 0.0002973341922389158.\n",
      "5760/5760 [==============================] - 10s 2ms/step - loss: 2.2137 - categorical_accuracy: 0.1837 - val_loss: 2.1511 - val_categorical_accuracy: 0.2391\n",
      "\n",
      "Epoch 00002: val_categorical_accuracy did not improve from 0.52656\n",
      "Epoch 3/25\n",
      "\n",
      "Epoch 00003: LearningRateScheduler setting learning rate to 0.0002946920729145618.\n",
      "5760/5760 [==============================] - 10s 2ms/step - loss: 2.0177 - categorical_accuracy: 0.3333 - val_loss: 1.8885 - val_categorical_accuracy: 0.3672\n",
      "\n",
      "Epoch 00003: val_categorical_accuracy did not improve from 0.52656\n",
      "Epoch 4/25\n",
      "\n",
      "Epoch 00004: LearningRateScheduler setting learning rate to 0.0002920734315308764.\n",
      "5760/5760 [==============================] - 10s 2ms/step - loss: 1.7722 - categorical_accuracy: 0.3915 - val_loss: 1.7434 - val_categorical_accuracy: 0.3891\n",
      "\n",
      "Epoch 00004: val_categorical_accuracy did not improve from 0.52656\n",
      "Epoch 5/25\n",
      "\n",
      "Epoch 00005: LearningRateScheduler setting learning rate to 0.00028947805946227145.\n",
      "5760/5760 [==============================] - 10s 2ms/step - loss: 1.6081 - categorical_accuracy: 0.4361 - val_loss: 1.6780 - val_categorical_accuracy: 0.4125\n",
      "\n",
      "Epoch 00005: val_categorical_accuracy did not improve from 0.52656\n",
      "Epoch 6/25\n",
      "\n",
      "Epoch 00006: LearningRateScheduler setting learning rate to 0.0002869057499370111.\n",
      "5760/5760 [==============================] - 10s 2ms/step - loss: 1.4787 - categorical_accuracy: 0.4755 - val_loss: 1.6422 - val_categorical_accuracy: 0.4219\n",
      "\n",
      "Epoch 00006: val_categorical_accuracy did not improve from 0.52656\n",
      "Epoch 7/25\n",
      "\n",
      "Epoch 00007: LearningRateScheduler setting learning rate to 0.00028435629802073855.\n",
      "5760/5760 [==============================] - 10s 2ms/step - loss: 1.3632 - categorical_accuracy: 0.5266 - val_loss: 1.6068 - val_categorical_accuracy: 0.4437\n",
      "\n",
      "Epoch 00007: val_categorical_accuracy did not improve from 0.52656\n",
      "Epoch 8/25\n",
      "\n",
      "Epoch 00008: LearningRateScheduler setting learning rate to 0.00028182950060014905.\n",
      "5760/5760 [==============================] - 10s 2ms/step - loss: 1.2572 - categorical_accuracy: 0.5686 - val_loss: 1.6100 - val_categorical_accuracy: 0.4516\n",
      "\n",
      "Epoch 00008: val_categorical_accuracy did not improve from 0.52656\n",
      "Epoch 9/25\n",
      "\n",
      "Epoch 00009: LearningRateScheduler setting learning rate to 0.0002793251563668079.\n",
      "5760/5760 [==============================] - 10s 2ms/step - loss: 1.1520 - categorical_accuracy: 0.6016 - val_loss: 1.6498 - val_categorical_accuracy: 0.4453\n",
      "\n",
      "Epoch 00009: val_categorical_accuracy did not improve from 0.52656\n",
      "Epoch 10/25\n",
      "\n",
      "Epoch 00010: LearningRateScheduler setting learning rate to 0.00027684306580111226.\n",
      "5760/5760 [==============================] - 10s 2ms/step - loss: 1.0689 - categorical_accuracy: 0.6351 - val_loss: 1.6909 - val_categorical_accuracy: 0.4422\n",
      "\n",
      "Epoch 00010: val_categorical_accuracy did not improve from 0.52656\n",
      "Epoch 11/25\n",
      "\n",
      "Epoch 00011: LearningRateScheduler setting learning rate to 0.0002743830311563958.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5760/5760 [==============================] - 10s 2ms/step - loss: 0.9830 - categorical_accuracy: 0.6627 - val_loss: 1.6899 - val_categorical_accuracy: 0.4578\n",
      "\n",
      "Epoch 00011: val_categorical_accuracy did not improve from 0.52656\n",
      "Epoch 12/25\n",
      "\n",
      "Epoch 00012: LearningRateScheduler setting learning rate to 0.00027194485644317407.\n",
      "5760/5760 [==============================] - 10s 2ms/step - loss: 0.8967 - categorical_accuracy: 0.7069 - val_loss: 1.7682 - val_categorical_accuracy: 0.4453\n",
      "\n",
      "Epoch 00012: val_categorical_accuracy did not improve from 0.52656\n",
      "Epoch 13/25\n",
      "\n",
      "Epoch 00013: LearningRateScheduler setting learning rate to 0.0002695283474135303.\n",
      "5760/5760 [==============================] - 10s 2ms/step - loss: 0.8310 - categorical_accuracy: 0.7314 - val_loss: 1.7820 - val_categorical_accuracy: 0.4547\n",
      "\n",
      "Epoch 00013: val_categorical_accuracy did not improve from 0.52656\n",
      "Epoch 14/25\n",
      "\n",
      "Epoch 00014: LearningRateScheduler setting learning rate to 0.0002671333115456397.\n",
      "5760/5760 [==============================] - 10s 2ms/step - loss: 0.7573 - categorical_accuracy: 0.7655 - val_loss: 1.8242 - val_categorical_accuracy: 0.4609\n",
      "\n",
      "Epoch 00014: val_categorical_accuracy did not improve from 0.52656\n",
      "Epoch 15/25\n",
      "\n",
      "Epoch 00015: LearningRateScheduler setting learning rate to 0.0002647595580284314.\n",
      "5760/5760 [==============================] - 10s 2ms/step - loss: 0.7254 - categorical_accuracy: 0.7753 - val_loss: 1.8297 - val_categorical_accuracy: 0.4641\n",
      "\n",
      "Epoch 00015: val_categorical_accuracy did not improve from 0.52656\n",
      "Epoch 16/25\n",
      "\n",
      "Epoch 00016: LearningRateScheduler setting learning rate to 0.00026240689774638675.\n",
      "5760/5760 [==============================] - 10s 2ms/step - loss: 0.6608 - categorical_accuracy: 0.7951 - val_loss: 1.9046 - val_categorical_accuracy: 0.4594\n",
      "\n",
      "Epoch 00016: val_categorical_accuracy did not improve from 0.52656\n",
      "Epoch 17/25\n",
      "\n",
      "Epoch 00017: LearningRateScheduler setting learning rate to 0.00026007514326447225.\n",
      "5760/5760 [==============================] - 10s 2ms/step - loss: 0.6174 - categorical_accuracy: 0.8146 - val_loss: 1.9637 - val_categorical_accuracy: 0.4484\n",
      "\n",
      "Epoch 00017: val_categorical_accuracy did not improve from 0.52656\n",
      "Epoch 00017: early stopping\n",
      "models num: 10\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for train_index , val_index in kf.split(raw_texts):\n",
    "    #print(len(texts))\n",
    "    #print(len(labels))\n",
    "    #print(train_index)\n",
    "    texts =[raw_texts[j] for j in train_index]\n",
    "    labels =  [raw_labels[j] for j in train_index]\n",
    "    #print(val_index)\n",
    "    \n",
    "    texts_val, labels_val = [raw_texts[j] for j in val_index], [raw_labels[j] for j in val_index]\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit(labels)\n",
    "    encoder_target = encoder.transform(labels)\n",
    "    dummy_target = krs.utils.np_utils.to_categorical(encoder_target) \n",
    "    encoder_target_val = encoder.transform(labels_val)\n",
    "    dummy_target_val = krs.utils.np_utils.to_categorical(encoder_target_val)\n",
    "    # 文本分词：\n",
    "    texts = [\".\".join(t.split(' ')) for t in texts]\n",
    "    texts_val = [\".\".join(t.split(' ')) for t in texts_val]\n",
    "    text_processed = np.array(list(vocab_processor.fit_transform(texts)))\n",
    "    text_processed_val = np.array(list(vocab_processor.fit_transform(texts_val)))\n",
    "    lr_schedule = LearningRateExponentialDecay(0.0003, EPOCH, 0.80)\n",
    "    lr = krs.callbacks.LearningRateScheduler(lr_schedule, verbose=1)\n",
    "    history = models[i].fit(x=text_processed, y=dummy_target, batch_size=BATCH_SIZE,\n",
    "                    epochs=EPOCH, validation_data=(text_processed_val, dummy_target_val),\n",
    "                    callbacks=[ckpt, earlystop, lr], verbose=1)\n",
    "    i = i+1\n",
    "    print(\"models num:\", i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T11:58:25.503550Z",
     "start_time": "2021-01-04T11:58:25.500926Z"
    }
   },
   "outputs": [],
   "source": [
    "def softmax_to_onehot(result):\n",
    "    result = np.argmax(result, axis=1)\n",
    "    one_hot = np.zeros((len(result),10))\n",
    "    one_hot[np.arange(len(result)),result] =1\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T11:58:34.775628Z",
     "start_time": "2021-01-04T11:58:26.539680Z"
    }
   },
   "outputs": [],
   "source": [
    "y = softmax_to_onehot(models[0].predict(text_processed_test))\n",
    "for i in range(1,10):\n",
    "    y = y+ softmax_to_onehot(models[i].predict(text_processed_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 此处y仅为BiLSTM模型的predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T11:58:39.255695Z",
     "start_time": "2021-01-04T11:58:39.252277Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 4, 4, 9, 6, 8, 0, 2, 9, 4, 0, 7, 9, 7, 7, 9, 1, 2, 9, 2, 8, 8, 2, 9, 3, 9, 7, 9, 9, 2, 3, 5, 9, 0, 9, 0, 2, 4, 5, 6, 8, 2, 8, 6, 3, 6, 2, 9, 5, 4, 6, 1, 6, 0, 9, 7, 0, 9, 2, 9, 5, 7, 0, 5, 1, 9, 8, 9, 0, 7, 1, 6, 0, 3, 2, 9, 1, 9, 6, 6, 6, 9, 1, 2, 2, 9, 4, 7, 9, 6, 2, 9, 4, 1, 9, 0, 9, 1, 8, 0]\n"
     ]
    }
   ],
   "source": [
    "y_test = np.argmax(y,axis=1)\n",
    "#y_test[1:100]\n",
    "y_test = list(y_test)\n",
    "print(y_test[0:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T12:51:00.512472Z",
     "start_time": "2021-01-04T12:51:00.508843Z"
    }
   },
   "source": [
    "# TF-IDF 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T11:05:44.576924Z",
     "start_time": "2021-01-04T11:05:44.571638Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_data(path):\n",
    "    label_list, text_list = [], []\n",
    "    k = 0\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        for line in f :\n",
    "            k += 1\n",
    "            text = line.strip().split('\\t')\n",
    "            label_list.append(labels_dict[text[2]]) #返回label的值\n",
    "            #print(k)\n",
    "            #print(line)\n",
    "            text_list.append(text[3])\n",
    "    return text_list, label_list\n",
    "\n",
    "def read_test_data(path):\n",
    "    text_list = []\n",
    "    k = 0\n",
    "    with open(path, 'r', encoding= 'utf-8') as f:\n",
    "        for line in f :\n",
    "            text =line.strip().split('\\n')\n",
    "            text = text[0]\n",
    "            text_list.append(text)\n",
    "    return text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T11:53:55.133573Z",
     "start_time": "2021-01-04T11:53:55.008913Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_dict shape: 16383\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = read_data(train_process_path)\n",
    "x_test = read_test_data(test_process_path)\n",
    "\n",
    "tfidf_model = TfidfVectorizer(stop_words='english').fit(x_train)\n",
    "print(f'word_dict shape: {len(tfidf_model.vocabulary_)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T11:53:57.863025Z",
     "start_time": "2021-01-04T11:53:56.070503Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 528,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_vec = tfidf_model.transform(x_train) # 节省空间，csr格式系数矩阵\n",
    "x_test_vec = tfidf_model.transform(x_test)\n",
    "\n",
    "clf = LogisticRegression(solver='lbfgs')  # 求解器使用lbfgs，其他使用默认超参数\n",
    "clf.fit(x_train_vec,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T11:53:04.433226Z",
     "start_time": "2021-01-04T11:53:04.426258Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1600"
      ]
     },
     "execution_count": 519,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_2 = clf.predict(x_test_vec)\n",
    "len(y_test_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型融合时令其权重为2.5:10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T12:23:15.093288Z",
     "start_time": "2021-01-04T12:23:15.069219Z"
    }
   },
   "outputs": [],
   "source": [
    "def labels_to_onehot(result):\n",
    "    result = np.array(result, dtype = int)\n",
    "    one_hot = np.zeros((len(result),10))\n",
    "    one_hot[np.arange(len(result)), result] = 2.5\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T12:23:15.750302Z",
     "start_time": "2021-01-04T12:23:15.720746Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 2.5],\n",
       "       [0. , 0. , 2.5, 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 2.5],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 2.5, 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 2.5],\n",
       "       [2.5, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 2.5],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 2.5],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 2.5]])"
      ]
     },
     "execution_count": 559,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_to_onehot(y_test_2)[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T12:23:16.653671Z",
     "start_time": "2021-01-04T12:23:16.650510Z"
    }
   },
   "outputs": [],
   "source": [
    "y = y+ labels_to_onehot(y_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T12:23:17.463910Z",
     "start_time": "2021-01-04T12:23:17.458459Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 4, 4, 9, 6, 8, 0, 2, 9, 4, 0, 7, 9, 7, 7, 8, 1, 2, 9, 9, 8, 8, 2, 9, 3, 9, 7, 9, 9, 2, 3, 5, 9, 0, 9, 0, 6, 4, 5, 6, 9, 2, 8, 9, 3, 6, 2, 9, 5, 4, 6, 2, 6, 0, 9, 7, 0, 9, 2, 9, 5, 7, 0, 5, 1, 9, 9, 9, 0, 7, 1, 6, 0, 3, 2, 9, 1, 9, 6, 6, 6, 9, 1, 2, 2, 6, 4, 7, 9, 9, 2, 9, 4, 1, 9, 0, 9, 1, 8, 0]\n"
     ]
    }
   ],
   "source": [
    "y_test = np.argmax(y,axis=1)\n",
    "#y_test[1:100]\n",
    "y_test = list(y_test)\n",
    "print(y_test[0:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预测结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T12:23:19.514697Z",
     "start_time": "2021-01-04T12:23:19.274716Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels_id = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "x = [i for i in range(len(labels_id))]\n",
    "count_in_train = [y_test.count(label) / len(y_test) for label in range(10)]  # 统计训练集占比\n",
    "plt.figure()\n",
    "plt.bar(x, count_in_train, width=0.5, label=\"test_set\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T11:58:50.566614Z",
     "start_time": "2021-01-04T11:58:50.559788Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('./result/results.txt','w', encoding='utf-8') as f:\n",
    "    for i in range(len(y_test)):\n",
    "        line = LABEL_INDEX[int(y_test[i])]\n",
    "        f.write(str(line) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T08:40:08.140178Z",
     "start_time": "2021-01-04T08:40:08.137154Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T08:40:10.957000Z",
     "start_time": "2021-01-04T08:40:10.336649Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels_id = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "x = [i for i in range(len(labels_id))]\n",
    "count_in_train = [labels.count(label) / len(labels) for label in labels_id]  # 统计训练集占比\n",
    "plt.figure()\n",
    "plt.bar(x, count_in_train, width=0.5, label=\"train_set\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T11:18:03.352216Z",
     "start_time": "2021-01-04T11:18:03.343207Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('./result/results.txt','w', encoding='utf-8') as f:\n",
    "    for i in range(len(y_test)):\n",
    "        line = LABEL_INDEX[int(y_test[i])]\n",
    "        f.write(str(line) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lable on val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-01T05:29:39.955005Z",
     "start_time": "2021-01-01T05:29:39.816063Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels_id = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "x = [i for i in range(len(labels_id))]\n",
    "count_in_train = [labels_val.count(label) / len(labels_val) for label in labels_id]  # 统计训练集占比\n",
    "plt.figure()\n",
    "plt.bar(x, count_in_train, width=0.5, label=\"val_set\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T08:41:08.205167Z",
     "start_time": "2021-01-04T08:41:08.192163Z"
    }
   },
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(labels)\n",
    "encoder_target = encoder.transform(labels)\n",
    "\n",
    "dummy_target = krs.utils.np_utils.to_categorical(encoder_target) \n",
    "# each one in dummy_target is a one-hot vector:,eg.  [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T08:41:10.626714Z",
     "start_time": "2021-01-04T08:41:10.621329Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6 9 1 9 7 9 0 5 3 5]\n",
      "[[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(encoder_target[:10])\n",
    "print(dummy_target[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-01T05:29:42.923063Z",
     "start_time": "2021-01-01T05:29:42.919207Z"
    }
   },
   "outputs": [],
   "source": [
    "encoder_target_val = encoder.transform(labels_val)\n",
    "dummy_target_val = krs.utils.np_utils.to_categorical(encoder_target_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-01T05:29:43.803354Z",
     "start_time": "2021-01-01T05:29:43.792059Z"
    }
   },
   "outputs": [],
   "source": [
    "# 文本分词：\n",
    "texts = [\".\".join(t.split(' ')) for t in texts]\n",
    "texts_val = [\".\".join(t.split(' ')) for t in texts_val]\n",
    "# 去掉空格，每个词用逗号隔开，如: \n",
    "#'The.child.was.carefully.wrapped.and.bound.into.the.cradle.by.means.of.a.cord'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-01T06:20:10.781854Z",
     "start_time": "2021-01-01T06:20:10.778789Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the.body.of.her.nephew.was.in.a.suitcase.under.the.bed'"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-01T06:20:11.239081Z",
     "start_time": "2021-01-01T06:20:11.235698Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nlen_result = []\\nfor i in range(len(texts_test)):\\n    len_result.append(len(texts_test[i].split()))\\nmax(len_result)\\n'"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "len_result = []\n",
    "for i in range(len(texts_test)):\n",
    "    len_result.append(len(texts_test[i].split()))\n",
    "max(len_result)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-01T06:20:12.036042Z",
     "start_time": "2021-01-01T06:20:11.726080Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (600, 83)\n"
     ]
    }
   ],
   "source": [
    "# word2vec 词袋化\n",
    "vocab_processor = tf.contrib.learn.preprocessing.VocabularyProcessor(max_sequence_length,min_frequency=0)\n",
    "\n",
    "\n",
    "#\n",
    "text_processed_test = np.array(list(vocab_processor.fit_transform(texts_test)))\n",
    "\n",
    "text_processed = np.array(list(vocab_processor.fit_transform(texts)))\n",
    "text_processed_val = np.array(list(vocab_processor.fit_transform(texts_val)))\n",
    "\n",
    "text_processed_test = np.array(list(vocab_processor.fit_transform(texts_test))) # 先编码测试集！\n",
    "\n",
    "print(type(text_processed_val),text_processed_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-01T06:20:12.262489Z",
     "start_time": "2021-01-01T06:20:12.237492Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<UNK>': 0,\n",
       " 'the': 1,\n",
       " 'body': 2,\n",
       " 'of': 3,\n",
       " 'her': 4,\n",
       " 'nephew': 5,\n",
       " 'was': 6,\n",
       " 'in': 7,\n",
       " 'a': 8,\n",
       " 'suitcase': 9,\n",
       " 'under': 10,\n",
       " 'bed': 11,\n",
       " 'drama': 12,\n",
       " 'unfolded': 13,\n",
       " 'shortly': 14,\n",
       " 'after': 15,\n",
       " '7pm': 16,\n",
       " 'last': 17,\n",
       " 'tuesday': 18,\n",
       " 'december': 19,\n",
       " '22': 20,\n",
       " 'when': 21,\n",
       " 'glyn': 22,\n",
       " 'saw': 23,\n",
       " 'that': 24,\n",
       " 'smoke': 25,\n",
       " 'coming': 26,\n",
       " 'from': 27,\n",
       " 'bonfire': 28,\n",
       " 'prior': 29,\n",
       " 'to': 30,\n",
       " '4004': 31,\n",
       " 'engineers': 32,\n",
       " 'built': 33,\n",
       " 'computers': 34,\n",
       " 'either': 35,\n",
       " 'collections': 36,\n",
       " 'chips': 37,\n",
       " 'or': 38,\n",
       " 'discrete': 39,\n",
       " 'components': 40,\n",
       " 'effective': 41,\n",
       " 'utilization': 42,\n",
       " 'cluster': 43,\n",
       " 'workstations': 44,\n",
       " 'for': 45,\n",
       " 'implementation': 46,\n",
       " 'scientific': 47,\n",
       " 'application': 48,\n",
       " 'requires': 49,\n",
       " 'highly': 50,\n",
       " 'flexible': 51,\n",
       " 'software': 52,\n",
       " 'environment': 53,\n",
       " 'player': 54,\n",
       " 'manipulates': 55,\n",
       " 'keyboard': 56,\n",
       " 'mouse': 57,\n",
       " 'joystick': 58,\n",
       " 'as': 59,\n",
       " 'game': 60,\n",
       " 'scene': 61,\n",
       " 'is': 62,\n",
       " 'displayed': 63,\n",
       " 'on': 64,\n",
       " 'video': 65,\n",
       " 'monitor': 66,\n",
       " 'like': 67,\n",
       " 'tarps': 68,\n",
       " 'plus': 69,\n",
       " 'has': 70,\n",
       " 'best': 71,\n",
       " 'painters': 72,\n",
       " 'market': 73,\n",
       " 'nasal': 74,\n",
       " 'dryness': 75,\n",
       " 'causes': 76,\n",
       " 'nosebleeds': 77,\n",
       " 'coughing': 78,\n",
       " 'wheezing': 79,\n",
       " 'and': 80,\n",
       " 'other': 81,\n",
       " 'short-term': 82,\n",
       " 'respiratory': 83,\n",
       " 'problems': 84,\n",
       " 'building': 85,\n",
       " 'surrounded': 86,\n",
       " 'by': 87,\n",
       " 'police': 88,\n",
       " 'who': 89,\n",
       " 'arrested': 90,\n",
       " 'three': 91,\n",
       " 'people': 92,\n",
       " 'they': 93,\n",
       " 'tried': 94,\n",
       " 'gain': 95,\n",
       " 'access': 96,\n",
       " 'this': 97,\n",
       " 'beautiful': 98,\n",
       " 're-imagining': 99,\n",
       " 'story': 100,\n",
       " 'starts': 101,\n",
       " 'an': 102,\n",
       " 'orphanage': 103,\n",
       " 'moves': 104,\n",
       " 'magical': 105,\n",
       " 'land': 106,\n",
       " 'where': 107,\n",
       " 'sweets': 108,\n",
       " 'have': 109,\n",
       " 'sexual': 110,\n",
       " 'subtext': 111,\n",
       " 'parker': 112,\n",
       " 'dunlap': 113,\n",
       " 'startled': 114,\n",
       " 'genie': 115,\n",
       " 'popped': 116,\n",
       " 'out': 117,\n",
       " 'old': 118,\n",
       " 'beat-up': 119,\n",
       " 'lamp': 120,\n",
       " 'colds': 121,\n",
       " 'flu': 122,\n",
       " 'cause': 123,\n",
       " 'inflammation': 124,\n",
       " 'mucous': 125,\n",
       " 'membranes': 126,\n",
       " 'nose': 127,\n",
       " 'throat': 128,\n",
       " 'mouth': 129,\n",
       " '1646': 130,\n",
       " 'however': 131,\n",
       " 'puritan': 132,\n",
       " 'emphasis': 133,\n",
       " 'upon': 134,\n",
       " 'individualism': 135,\n",
       " 'individual': 136,\n",
       " 'conscience': 137,\n",
       " 'made': 138,\n",
       " 'it': 139,\n",
       " 'impossible': 140,\n",
       " 'movement': 141,\n",
       " 'form': 142,\n",
       " 'national': 143,\n",
       " 'presbyterian': 144,\n",
       " 'church': 145,\n",
       " '1662': 146,\n",
       " 'anglican': 147,\n",
       " 're-established': 148,\n",
       " 'puritanism': 149,\n",
       " 'had': 150,\n",
       " 'become': 151,\n",
       " 'loose': 152,\n",
       " 'confederation': 153,\n",
       " 'various': 154,\n",
       " 'dissenting': 155,\n",
       " 'sects': 156,\n",
       " 'internal': 157,\n",
       " 'payoff': 158,\n",
       " 'rooted': 159,\n",
       " 'psychological': 160,\n",
       " 'cost': 161,\n",
       " 'preference': 162,\n",
       " 'falsification': 163,\n",
       " 'officials': 164,\n",
       " 'northern': 165,\n",
       " 'chinese': 166,\n",
       " 'province': 167,\n",
       " 'inner': 168,\n",
       " 'mongolia': 169,\n",
       " 'mobilized': 170,\n",
       " '33': 171,\n",
       " '000': 172,\n",
       " 'stop': 173,\n",
       " 'swarm': 174,\n",
       " 'locusts': 175,\n",
       " '267': 176,\n",
       " 'miles': 177,\n",
       " 'outside': 178,\n",
       " 'beijing': 179,\n",
       " 'mehmet': 180,\n",
       " 'oz': 181,\n",
       " 'cardiovascular': 182,\n",
       " 'surgeon': 183,\n",
       " 'part': 184,\n",
       " 'new': 185,\n",
       " 'generation': 186,\n",
       " 'doctors': 187,\n",
       " 'are': 188,\n",
       " 'taking': 189,\n",
       " 'medicine': 190,\n",
       " 'technological': 191,\n",
       " 'spiritual': 192,\n",
       " 'frontiers': 193,\n",
       " 'government': 194,\n",
       " 'spended': 195,\n",
       " 'following': 196,\n",
       " '18': 197,\n",
       " 'months': 198,\n",
       " 'before': 199,\n",
       " 'elections': 200,\n",
       " 'similar': 201,\n",
       " 'vein': 202,\n",
       " '-': 203,\n",
       " 'shooting': 204,\n",
       " 'whole': 205,\n",
       " 'lead': 206,\n",
       " 'conservative': 207,\n",
       " 'foxes': 208,\n",
       " 'extend': 209,\n",
       " 'metaphor': 210,\n",
       " 'namely': 211,\n",
       " 'heathrow': 212,\n",
       " 'royal': 213,\n",
       " 'mail': 214,\n",
       " 'privatisation': 215,\n",
       " 'quickly': 216,\n",
       " 'but': 217,\n",
       " 'neatly': 218,\n",
       " 'secretary': 219,\n",
       " 'tore': 220,\n",
       " 'side': 221,\n",
       " 'open': 222,\n",
       " 'with': 223,\n",
       " 'letter': 224,\n",
       " 'opener': 225,\n",
       " 'pulling': 226,\n",
       " 'yet': 227,\n",
       " 'another': 228,\n",
       " 'sheet': 229,\n",
       " 'paper': 230,\n",
       " 'first': 231,\n",
       " 'british': 232,\n",
       " 'steam': 233,\n",
       " 'powered': 234,\n",
       " 'vibrator': 235,\n",
       " 'dates': 236,\n",
       " 'back': 237,\n",
       " 'early': 238,\n",
       " '1880s': 239,\n",
       " 'developed': 240,\n",
       " 'american': 241,\n",
       " 'physician': 242,\n",
       " 'i': 243,\n",
       " 'love': 244,\n",
       " 'imperial': 245,\n",
       " 'logo': 246,\n",
       " 'at': 247,\n",
       " 'end': 248,\n",
       " 'tank': 249,\n",
       " 'canons': 250,\n",
       " 'efficiency': 251,\n",
       " 'teachers': 252,\n",
       " 'taken': 253,\n",
       " 'during': 254,\n",
       " 'past': 255,\n",
       " 'seven': 256,\n",
       " 'years': 257,\n",
       " 'no': 258,\n",
       " 'time': 259,\n",
       " 'been': 260,\n",
       " 'better': 261,\n",
       " 'than': 262,\n",
       " 'year': 263,\n",
       " 'international': 264,\n",
       " 'monthly': 265,\n",
       " 'magazine': 266,\n",
       " 'dedicated': 267,\n",
       " 'all': 268,\n",
       " 'forms': 269,\n",
       " 'contemporary': 270,\n",
       " 'sculpture': 271,\n",
       " 'chapter': 272,\n",
       " 'gives': 273,\n",
       " 'introduction': 274,\n",
       " 'brief': 275,\n",
       " 'overview': 276,\n",
       " 'most': 277,\n",
       " 'important': 278,\n",
       " 'optimization': 279,\n",
       " 'techniques': 280,\n",
       " 'defra': 281,\n",
       " 'identified': 282,\n",
       " 'different': 283,\n",
       " 'noises': 284,\n",
       " 'dogs': 285,\n",
       " 'meanings': 286,\n",
       " 'behind': 287,\n",
       " 'them': 288,\n",
       " 'project': 289,\n",
       " 'process': 290,\n",
       " 'comprised': 291,\n",
       " 'field': 292,\n",
       " 'study': 293,\n",
       " 'istanbul': 294,\n",
       " 'inhabitants': 295,\n",
       " '4': 296,\n",
       " 'weeks': 297,\n",
       " 'presentations': 298,\n",
       " '8': 299,\n",
       " 'there': 300,\n",
       " 'actual': 301,\n",
       " 'world': 302,\n",
       " 'records': 303,\n",
       " 'kookiest': 304,\n",
       " 'hat': 305,\n",
       " 'longest': 306,\n",
       " 'message': 307,\n",
       " 'bottle': 308,\n",
       " 'sea': 309,\n",
       " 'tallest': 310,\n",
       " 'scarecrow': 311,\n",
       " 'annulment': 312,\n",
       " 'legal': 313,\n",
       " 'procedure': 314,\n",
       " 'declaring': 315,\n",
       " 'marriage': 316,\n",
       " 'null': 317,\n",
       " 'void': 318,\n",
       " 'also': 319,\n",
       " 'large': 320,\n",
       " 'convocation': 321,\n",
       " 'bald': 322,\n",
       " 'eagles': 323,\n",
       " 'near': 324,\n",
       " 'park': 325,\n",
       " 'entrance': 326,\n",
       " 'provides': 327,\n",
       " 'excellent': 328,\n",
       " 'viewing': 329,\n",
       " 'opportunities': 330,\n",
       " 'summer': 331,\n",
       " 'goalkeeper': 332,\n",
       " 'helped': 333,\n",
       " 'team': 334,\n",
       " 'advance': 335,\n",
       " 'finals': 336,\n",
       " 'w-league': 337,\n",
       " 'tournament': 338,\n",
       " 'pilgrims': 339,\n",
       " 'rejoiced': 340,\n",
       " 'located': 341,\n",
       " 'skein': 342,\n",
       " 'wild': 343,\n",
       " 'fowl': 344,\n",
       " 'their': 345,\n",
       " 'thanksgiving': 346,\n",
       " 'tables': 347,\n",
       " \"daborne's\": 348,\n",
       " 'play': 349,\n",
       " 'about': 350,\n",
       " 'historic': 351,\n",
       " 'person': 352,\n",
       " 'pirate': 353,\n",
       " 'ward': 354,\n",
       " 'famous': 355,\n",
       " 'england': 356,\n",
       " 'its': 357,\n",
       " 'writing': 358,\n",
       " 'stored': 359,\n",
       " 'wine': 360,\n",
       " 'cool': 361,\n",
       " 'temperature': 362,\n",
       " 'company': 363,\n",
       " 'moved': 364,\n",
       " 'into': 365,\n",
       " 'music': 366,\n",
       " 'business': 367,\n",
       " 'maryland': 368,\n",
       " 'department': 369,\n",
       " 'already': 370,\n",
       " 'worked': 371,\n",
       " 'reduce': 372,\n",
       " 'amount': 373,\n",
       " 'pollution': 374,\n",
       " 'sources': 375,\n",
       " 'cars': 376,\n",
       " 'factories': 377,\n",
       " 'soya': 378,\n",
       " 'farming': 379,\n",
       " 'one': 380,\n",
       " 'main': 381,\n",
       " 'tropical': 382,\n",
       " 'deforestation': 383,\n",
       " 'which': 384,\n",
       " 'currently': 385,\n",
       " 'produces': 386,\n",
       " 'fifth': 387,\n",
       " 'global': 388,\n",
       " 'climate': 389,\n",
       " 'change': 390,\n",
       " 'leader': 391,\n",
       " 'his': 392,\n",
       " 'comments': 393,\n",
       " 'he': 394,\n",
       " 'flew': 395,\n",
       " 'cameroon': 396,\n",
       " 'leg': 397,\n",
       " 'six-day': 398,\n",
       " 'trip': 399,\n",
       " 'will': 400,\n",
       " 'see': 401,\n",
       " 'him': 402,\n",
       " 'travelling': 403,\n",
       " 'angola': 404,\n",
       " 'encroaching': 405,\n",
       " 'darkness': 406,\n",
       " 'caused': 407,\n",
       " 'twin': 408,\n",
       " 'horrors': 409,\n",
       " 'war': 410,\n",
       " 'mysterious': 411,\n",
       " 'plague': 412,\n",
       " 'man': 413,\n",
       " 'grew': 414,\n",
       " 'human': 415,\n",
       " 'ear': 416,\n",
       " 'breakthrough': 417,\n",
       " 'brings': 418,\n",
       " 'prospect': 419,\n",
       " 'artificial': 420,\n",
       " 'liver': 421,\n",
       " 'much': 422,\n",
       " 'closer': 423,\n",
       " 'we': 424,\n",
       " 'watched': 425,\n",
       " 'barman': 426,\n",
       " 'poured': 427,\n",
       " 'alcohol': 428,\n",
       " 'bar': 429,\n",
       " 'absinthe': 430,\n",
       " 'couple': 431,\n",
       " 'shot': 432,\n",
       " 'glasses': 433,\n",
       " 'then': 434,\n",
       " 'lit': 435,\n",
       " 'lot': 436,\n",
       " 'playwright': 437,\n",
       " 'uses': 438,\n",
       " 'names': 439,\n",
       " 'device': 440,\n",
       " 'wordplay': 441,\n",
       " 'several': 442,\n",
       " 'points': 443,\n",
       " 'since': 444,\n",
       " 'complex': 445,\n",
       " 'stages': 446,\n",
       " 'discrepancies': 447,\n",
       " 'exist': 448,\n",
       " 'completion': 449,\n",
       " 'due': 450,\n",
       " 'differing': 451,\n",
       " 'opinions': 452,\n",
       " 'mason': 453,\n",
       " 'removed': 454,\n",
       " 'original': 455,\n",
       " 'left': 456,\n",
       " 'right': 457,\n",
       " 'edges': 458,\n",
       " 'place': 459,\n",
       " 'prepared': 460,\n",
       " 'simple': 461,\n",
       " 'moulding': 462,\n",
       " 'each': 463,\n",
       " 'second': 464,\n",
       " 'section': 465,\n",
       " 'authors': 466,\n",
       " 'explore': 467,\n",
       " 'factors': 468,\n",
       " 'ostensibly': 469,\n",
       " 'unrelated': 470,\n",
       " 'race': 471,\n",
       " 'nonetheless': 472,\n",
       " 'contribute': 473,\n",
       " 'racial': 474,\n",
       " 'inequality': 475,\n",
       " 'particular': 476,\n",
       " 'ratpack': 477,\n",
       " 'colonels': 478,\n",
       " 'development': 479,\n",
       " 'worst': 480,\n",
       " 'possible': 481,\n",
       " 'handle': 482,\n",
       " 'relations': 483,\n",
       " 'latin': 484,\n",
       " 'countries': 485,\n",
       " 'playlist': 486,\n",
       " 'enclosed': 487,\n",
       " 'small': 488,\n",
       " 'leather': 489,\n",
       " 'portfolio': 490,\n",
       " 'keep': 491,\n",
       " 'papers': 492,\n",
       " 'andaman': 493,\n",
       " 'islands': 494,\n",
       " 'fish': 495,\n",
       " 'captured': 496,\n",
       " 'convicts': 497,\n",
       " 'means': 498,\n",
       " 'weirs': 499,\n",
       " 'fixed': 500,\n",
       " 'across': 501,\n",
       " 'openings': 502,\n",
       " 'creeks': 503,\n",
       " 'many': 504,\n",
       " 'joined': 505,\n",
       " 'armada': 506,\n",
       " 'sailing': 507,\n",
       " 'ships': 508,\n",
       " 'sailed': 509,\n",
       " 'belfast': 510,\n",
       " 'dublin': 511,\n",
       " 'cork': 512,\n",
       " 'holyhead': 513,\n",
       " 'liverpool': 514,\n",
       " 'glasgow': 515,\n",
       " 'bound': 516,\n",
       " 'information': 517,\n",
       " 'summarises': 518,\n",
       " 'labour': 519,\n",
       " 'uk': 520,\n",
       " 'necklace': 521,\n",
       " 'locked': 522,\n",
       " 'safe': 523,\n",
       " 'room': 524,\n",
       " 'victor': 525,\n",
       " 'hugo': 526,\n",
       " 'hotel': 527,\n",
       " 'term': 528,\n",
       " 'derived': 529,\n",
       " 'root': 530,\n",
       " 'can': 531,\n",
       " 'mean': 532,\n",
       " 'both': 533,\n",
       " \"'to\": 534,\n",
       " 'be': 535,\n",
       " 'animal': 536,\n",
       " 'lowered': 537,\n",
       " 'until': 538,\n",
       " 'pelvic': 539,\n",
       " 'limbs': 540,\n",
       " 'touch': 541,\n",
       " 'floor': 542,\n",
       " 'solid': 543,\n",
       " 'supporting': 544,\n",
       " 'surface': 545,\n",
       " 'bob': 546,\n",
       " \"oblong's\": 547,\n",
       " 'suggestions': 548,\n",
       " 'used': 549,\n",
       " 'kindling': 550,\n",
       " 'factory': 551,\n",
       " \"'s\": 552,\n",
       " 'furnace': 553,\n",
       " 'laws': 554,\n",
       " 'apply': 555,\n",
       " 'officiating': 556,\n",
       " 'equipment': 557,\n",
       " 'procedures': 558,\n",
       " 'sport': 559,\n",
       " \"alzheimer's\": 560,\n",
       " 'disease': 561,\n",
       " 'degenerative': 562,\n",
       " 'brain': 563,\n",
       " 'disorder': 564,\n",
       " 'results': 565,\n",
       " 'memory': 566,\n",
       " 'loss': 567,\n",
       " 'impaired': 568,\n",
       " 'thinking': 569,\n",
       " 'difficulty': 570,\n",
       " 'finding': 571,\n",
       " 'word': 572,\n",
       " 'speaking': 573,\n",
       " 'personality': 574,\n",
       " 'changes': 575,\n",
       " 'winter': 576,\n",
       " 'virus': 577,\n",
       " 'rapidly': 578,\n",
       " 'spreading': 579,\n",
       " 'young': 580,\n",
       " 'children': 581,\n",
       " 'elderly': 582,\n",
       " \"wasn't\": 583,\n",
       " 'long': 584,\n",
       " 'crate': 585,\n",
       " 'way': 586,\n",
       " 'farm': 587,\n",
       " 'courtesy': 588,\n",
       " 'assistant': 589,\n",
       " 'course': 590,\n",
       " 'clock': 591,\n",
       " 'signal': 592,\n",
       " 'generated': 593,\n",
       " 'external': 594,\n",
       " 'cavity': 595,\n",
       " 'semiconductor': 596,\n",
       " 'laser': 597,\n",
       " 'deadline': 598,\n",
       " 'driven': 599,\n",
       " 'industry': 600,\n",
       " 'only': 601,\n",
       " 'minority': 602,\n",
       " 'armenian': 603,\n",
       " 'physicians': 604,\n",
       " 'felt': 605,\n",
       " 'well': 606,\n",
       " 'counsel': 607,\n",
       " 'patients': 608,\n",
       " 'quit': 609,\n",
       " 'smoking': 610,\n",
       " 'provincial': 611,\n",
       " 'title': 612,\n",
       " 'convincing': 613,\n",
       " '6-1': 614,\n",
       " 'victory': 615,\n",
       " 'over': 616,\n",
       " 'adversaries': 617,\n",
       " 'pas': 618,\n",
       " 'huskies': 619,\n",
       " '360': 620,\n",
       " 'bln': 621,\n",
       " 'yuan': 622,\n",
       " 'invested': 623,\n",
       " 'post-quake': 624,\n",
       " 'reconstruction': 625,\n",
       " 'university': 626,\n",
       " 'washington': 627,\n",
       " 'system': 628,\n",
       " 'named': 629,\n",
       " 'hubble': 630,\n",
       " 'looks': 631,\n",
       " 'these': 632,\n",
       " 'black': 633,\n",
       " 'holes': 634,\n",
       " 'maps': 635,\n",
       " 'web': 636,\n",
       " 'site': 637,\n",
       " 'providing': 638,\n",
       " 'ever-changing': 639,\n",
       " 'constellation': 640,\n",
       " \"internet's\": 641,\n",
       " 'weak': 642,\n",
       " 'landslides': 643,\n",
       " 'earthquakes': 644,\n",
       " 'aftershocks': 645,\n",
       " 'were': 646,\n",
       " 'concentrated': 647,\n",
       " 'along': 648,\n",
       " 'mudstone': 649,\n",
       " 'sandstone': 650,\n",
       " 'surfaces': 651,\n",
       " 'carefully': 652,\n",
       " 'hot': 653,\n",
       " 'coffee': 654,\n",
       " 'glass': 655,\n",
       " 'cup': 656,\n",
       " 'desperate': 657,\n",
       " 'clung': 658,\n",
       " 'stump': 659,\n",
       " 'battered': 660,\n",
       " 'rocks': 661,\n",
       " 'shuddering': 662,\n",
       " 'thump': 663,\n",
       " 'butlers': 664,\n",
       " 'sometimes': 665,\n",
       " 'known': 666,\n",
       " 'household': 667,\n",
       " 'managers': 668,\n",
       " 'respected': 669,\n",
       " 'head': 670,\n",
       " 'staff': 671,\n",
       " 'document': 672,\n",
       " 'makes': 673,\n",
       " 'significant': 674,\n",
       " 'contribution': 675,\n",
       " 'further': 676,\n",
       " 'clarification': 677,\n",
       " 'drinking': 678,\n",
       " 'water': 679,\n",
       " 'day': 680,\n",
       " 'heat': 681,\n",
       " 'exchanger': 682,\n",
       " 'installed': 683,\n",
       " 'fuel': 684,\n",
       " 'systemically': 685,\n",
       " 'dust': 686,\n",
       " 'fume': 687,\n",
       " 'irritation': 688,\n",
       " 'upper': 689,\n",
       " 'tract': 690,\n",
       " 'metallic': 691,\n",
       " 'taste': 692,\n",
       " 'nausea': 693,\n",
       " 'awoke': 694,\n",
       " 'find': 695,\n",
       " 'conjunction': 696,\n",
       " 'grammarians': 697,\n",
       " 'standing': 698,\n",
       " 'me': 699,\n",
       " 'observing': 700,\n",
       " 'my': 701,\n",
       " 'disposition': 702,\n",
       " 'look': 703,\n",
       " 'would': 704,\n",
       " 'put': 705,\n",
       " 'sneer': 706,\n",
       " 'shame': 707,\n",
       " 'disc': 708,\n",
       " 'box': 709,\n",
       " 'plays': 710,\n",
       " 'function': 711,\n",
       " 'pins': 712,\n",
       " 'perpendicular': 713,\n",
       " 'plane': 714,\n",
       " 'skin': 715,\n",
       " 'orange': 716,\n",
       " 'multiple': 717,\n",
       " 'benefits': 718,\n",
       " 'you': 719,\n",
       " 'take': 720,\n",
       " 'advantage': 721,\n",
       " 'contains': 722,\n",
       " 'flavonoids': 723,\n",
       " 'valuable': 724,\n",
       " 'component': 725,\n",
       " 'vitamin': 726,\n",
       " 'c': 727,\n",
       " 'noise': 728,\n",
       " 'sleep': 729,\n",
       " 'deprivation': 730,\n",
       " 'produced': 731,\n",
       " 'construction': 732,\n",
       " 'intolerable': 733,\n",
       " 'tuxedo': 734,\n",
       " 'banquet': 735,\n",
       " 'night': 736,\n",
       " 'peter': 737,\n",
       " \"rickham's\": 738,\n",
       " 'office': 739,\n",
       " 'option': 740,\n",
       " 'extra': 741,\n",
       " 'credit': 742,\n",
       " 'read': 743,\n",
       " 'completed': 744,\n",
       " 'parent': 745,\n",
       " 'book': 746,\n",
       " 'report': 747,\n",
       " 'teacher': 748,\n",
       " \"nrma's\": 749,\n",
       " 'president': 750,\n",
       " 'wendy': 751,\n",
       " 'machin': 752,\n",
       " 'chief': 753,\n",
       " 'executive': 754,\n",
       " 'tony': 755,\n",
       " 'stuart': 756,\n",
       " 'among': 757,\n",
       " 'members': 758,\n",
       " 'party': 759,\n",
       " 'viewed': 760,\n",
       " 'concert': 761,\n",
       " 'private': 762,\n",
       " 'picture': 763,\n",
       " 'top': 764,\n",
       " 'shows': 765,\n",
       " 'farmer': 766,\n",
       " 'genetically': 767,\n",
       " 'engineered': 768,\n",
       " 'cotton': 769,\n",
       " 'plant': 770,\n",
       " 'south': 771,\n",
       " 'africa': 772,\n",
       " '2003': 773,\n",
       " 'integrated': 774,\n",
       " 'production': 775,\n",
       " 'schemes': 776,\n",
       " 'crops': 777,\n",
       " 'may': 778,\n",
       " 'relevance': 779,\n",
       " 'sectors': 780,\n",
       " 'such': 781,\n",
       " 'dairy': 782,\n",
       " 'pen': 783,\n",
       " 'procured': 784,\n",
       " 'pocket': 785,\n",
       " 'lab': 786,\n",
       " 'coat': 787,\n",
       " 'jotted': 788,\n",
       " 'quick': 789,\n",
       " 'note': 790,\n",
       " 'spiral': 791,\n",
       " 'yelling': 792,\n",
       " 'chassis': 793,\n",
       " 'truck': 794,\n",
       " 'two': 795,\n",
       " 'wooden': 796,\n",
       " 'beams': 797,\n",
       " 'carry': 798,\n",
       " 'framework': 799,\n",
       " 'monorails': 800,\n",
       " 'throttle': 801,\n",
       " 'engine': 802,\n",
       " 'wide': 803,\n",
       " 'now': 804,\n",
       " 'roar': 805,\n",
       " 'emitted': 806,\n",
       " 'through': 807,\n",
       " 'vertical': 808,\n",
       " 'exhaust': 809,\n",
       " 'acting': 810,\n",
       " 'stack': 811,\n",
       " 'loud': 812,\n",
       " 'strangely': 813,\n",
       " 'comforting': 814,\n",
       " 'effort': 815,\n",
       " 'research': 816,\n",
       " 'phenomenon': 817,\n",
       " 'voltage': 818,\n",
       " 'collapse': 819,\n",
       " 'article': 820,\n",
       " 'use': 821,\n",
       " 'bench': 822,\n",
       " 'marks': 823,\n",
       " 'surveying': 824,\n",
       " 'mark': 825,\n",
       " \"it's\": 826,\n",
       " 'called': 827,\n",
       " 'symform': 828,\n",
       " 'stealthy': 829,\n",
       " 'seattle': 830,\n",
       " 'outfit': 831,\n",
       " 'founded': 832,\n",
       " 'pair': 833,\n",
       " 'ex-microsoft': 834,\n",
       " 'employees': 835,\n",
       " 'praerit': 836,\n",
       " 'garg': 837,\n",
       " 'bassam': 838,\n",
       " 'tabbara': 839,\n",
       " 'work': 840,\n",
       " 'researchers': 841,\n",
       " 'attest': 842,\n",
       " 'monopoles': 843,\n",
       " 'emergent': 844,\n",
       " 'states': 845,\n",
       " 'matter': 846,\n",
       " 'ie': 847,\n",
       " 'emerge': 848,\n",
       " 'special': 849,\n",
       " 'arrangements': 850,\n",
       " 'dipoles': 851,\n",
       " 'completely': 852,\n",
       " 'constituents': 853,\n",
       " 'material': 854,\n",
       " 'transmitter': 855,\n",
       " 'sends': 856,\n",
       " 'radio': 857,\n",
       " 'doorbell': 858,\n",
       " 'receiver': 859,\n",
       " 'inside': 860,\n",
       " 'statement': 861,\n",
       " 'group': 862,\n",
       " 'reiterated': 863,\n",
       " 'illegal': 864,\n",
       " 'create': 865,\n",
       " 'robot': 866,\n",
       " 'dead': 867,\n",
       " 'bodies': 868,\n",
       " 'energy': 869,\n",
       " 'source': 870,\n",
       " 'classic': 871,\n",
       " 'huffman': 872,\n",
       " 'photograph': 873,\n",
       " 'pictures': 874,\n",
       " 'cow': 875,\n",
       " 'hands': 876,\n",
       " 'set': 877,\n",
       " 'up': 878,\n",
       " 'camp': 879,\n",
       " 'remuda': 880,\n",
       " 'geldings': 881,\n",
       " 'trailing': 882,\n",
       " 'real-time': 883,\n",
       " 'dimensional': 884,\n",
       " 'echocardiography': 885,\n",
       " 'arrived': 886,\n",
       " 'our': 887,\n",
       " 'clinical': 888,\n",
       " 'cardiology': 889,\n",
       " 'allowing': 890,\n",
       " 'noninvasive': 891,\n",
       " 'repeatable': 892,\n",
       " 'spatial': 893,\n",
       " 'visualisation': 894,\n",
       " 'news': 895,\n",
       " 'broken': 896,\n",
       " 'engagement': 897,\n",
       " 'came': 898,\n",
       " 'hewitt': 899,\n",
       " 'snapped': 900,\n",
       " 'sobbing': 901,\n",
       " 'packed': 902,\n",
       " 'luggage': 903,\n",
       " 'vehicle': 904,\n",
       " 'home': 905,\n",
       " 'germans': 906,\n",
       " 'complained': 907,\n",
       " 'bitterly': 908,\n",
       " 'rostrum': 909,\n",
       " 'newspapers': 910,\n",
       " 'complaints': 911,\n",
       " 'reflected': 912,\n",
       " 'propaganda': 913,\n",
       " 'films': 914,\n",
       " 'regarding': 915,\n",
       " 'soldiers': 916,\n",
       " 'french': 917,\n",
       " 'colonial': 918,\n",
       " 'products': 919,\n",
       " 'manufactured': 920,\n",
       " 'firm': 921,\n",
       " 'still': 922,\n",
       " 'continue': 923,\n",
       " 'chiefly': 924,\n",
       " 'dyestuffs': 925,\n",
       " 'remainder': 926,\n",
       " 'reconstructed': 927,\n",
       " 'deryck': 928,\n",
       " 'cooke': 929,\n",
       " '1964': 930,\n",
       " 'extensive': 931,\n",
       " 'sketches': 932,\n",
       " 'composer': 933,\n",
       " 'specifying': 934,\n",
       " 'command': 935,\n",
       " 'once': 936,\n",
       " 'consumers': 937,\n",
       " 'execute': 938,\n",
       " 'using': 939,\n",
       " 'input': 940,\n",
       " 'parameters': 941,\n",
       " 'reminds': 942,\n",
       " \"broker's\": 943,\n",
       " 'prediction': 944,\n",
       " \"abc's\": 945,\n",
       " 'stock': 946,\n",
       " \"def's\": 947,\n",
       " 'next': 948,\n",
       " 'month': 949,\n",
       " 'same': 950,\n",
       " 'destruction': 951,\n",
       " 'economy': 952,\n",
       " 'running': 953,\n",
       " 'show': 954,\n",
       " 'so': 955,\n",
       " 'us': 956,\n",
       " 'down': 957,\n",
       " 'buy': 958,\n",
       " 'country': 959,\n",
       " 'cheap': 960,\n",
       " 'nuclear': 961,\n",
       " 'qualified': 962,\n",
       " 'electronics': 963,\n",
       " 'technicians': 964,\n",
       " 'sent': 965,\n",
       " 'aircraft': 966,\n",
       " 'carriers': 967,\n",
       " 'attaches': 968,\n",
       " 'flashlight': 969,\n",
       " 'rifle': 970,\n",
       " 'later': 971,\n",
       " 'discarded': 972,\n",
       " 'additionally': 973,\n",
       " 'record': 974,\n",
       " 'vietnam': 975,\n",
       " 'veteran': 976,\n",
       " 'documented': 977,\n",
       " 'recent': 978,\n",
       " 'cases': 979,\n",
       " 'reported': 980,\n",
       " 'media': 981,\n",
       " 'older': 982,\n",
       " \"woman's\": 983,\n",
       " 'baby': 984,\n",
       " 'stillborn': 985,\n",
       " 'because': 986,\n",
       " 'abnormal': 987,\n",
       " 'placeta': 988,\n",
       " 'miscarriages': 989,\n",
       " 'umbilical': 990,\n",
       " 'chord': 991,\n",
       " 'encircling': 992,\n",
       " 'fetus': 993,\n",
       " 'plan': 994,\n",
       " 'join': 995,\n",
       " 'convoy': 996,\n",
       " 'buses': 997,\n",
       " 'vans': 998,\n",
       " 'coasters': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_dic = vocab_processor.vocabulary_._mapping\n",
    "vocab_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-01T06:20:13.703372Z",
     "start_time": "2021-01-01T06:20:13.699856Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the.body.of.her.nephew.was.in.a.suitcase.under.the.bed\n",
      "[ 1  2  3  4  5  6  7  8  9 10  1 11  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "print(texts_test[0])\n",
    "#print(len(text_processed_test[0]))\n",
    "print(text_processed_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-01T06:20:14.184512Z",
     "start_time": "2021-01-01T06:20:14.181391Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the.author.of.a.keygen.uses.a.disassembler.to.look.at.the.raw.assembly.code\n",
      "[   1 1885    3    8    0  438    8    0   30  703  247    1 2164 6913\n",
      " 3955    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "print(texts[0])\n",
    "#print(len(text_processed_test[0]))\n",
    "print(text_processed[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-01T06:20:14.921834Z",
     "start_time": "2021-01-01T06:20:14.916610Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('<UNK>', 0), ('the', 1), ('body', 2), ('of', 3), ('her', 4), ('nephew', 5), ('was', 6), ('in', 7), ('a', 8), ('suitcase', 9), ('under', 10), ('bed', 11), ('drama', 12), ('unfolded', 13), ('shortly', 14), ('after', 15), ('7pm', 16), ('last', 17), ('tuesday', 18), ('december', 19)]\n"
     ]
    }
   ],
   "source": [
    "dict = vocab_processor.vocabulary_._mapping\n",
    "sorted_vocab = sorted(dict.items(), key=lambda x: x[1])\n",
    "print(sorted_vocab[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-01T06:20:15.347590Z",
     "start_time": "2021-01-01T06:20:15.345765Z"
    }
   },
   "outputs": [],
   "source": [
    "# 改小embedding size似乎仍然overfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-01T06:24:23.844268Z",
     "start_time": "2021-01-01T06:24:22.273716Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/ipykernel_launcher.py:6: UserWarning: The `dropout` argument is no longer support in `Embedding`. You can apply a `keras.layers.SpatialDropout1D` layer right after the `Embedding` layer to get the same behavior.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_11 (Embedding)     (None, 83, 100)           771500    \n",
      "_________________________________________________________________\n",
      "bidirectional_11 (Bidirectio (None, 200)               160800    \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                2010      \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 934,310\n",
      "Trainable params: 934,310\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_size = 100\n",
    "\n",
    "model = krs.Sequential()\n",
    "model.add(krs.layers.Embedding(len(dict.items()),\n",
    "                embedding_size, input_length = max_sequence_length,\n",
    "                 mask_zero= True  ,dropout = 0.2  ))\n",
    "model.add(krs.layers.Bidirectional(krs.layers.LSTM(100,dropout = 0.5)))\n",
    "model.add(krs.layers.Dense(10))\n",
    "model.add(krs.layers.Activation(\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-01T06:20:16.687178Z",
     "start_time": "2021-01-01T06:20:16.684109Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the.author.of.a.keygen.uses.a.disassembler.to.look.at.the.raw.assembly.code \n",
      " [   1 1885    3    8    0  438    8    0   30  703  247    1 2164 6913\n",
      " 3955    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "print(texts[0],'\\n',text_processed[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-01T06:20:16.765115Z",
     "start_time": "2021-01-01T06:20:16.762942Z"
    }
   },
   "outputs": [],
   "source": [
    "# -- 对于多分类问题：应该选用下面的loss和acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-01T06:20:17.084548Z",
     "start_time": "2021-01-01T06:20:17.026573Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(loss = \"categorical_crossentropy\", optimizer= \"adam\", metrics=[\"categorical_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-01T06:20:26.377516Z",
     "start_time": "2021-01-01T06:20:26.375203Z"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "EPOCH = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-01T06:20:26.839619Z",
     "start_time": "2021-01-01T06:20:26.835845Z"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "EPOCH = 25\n",
    "ckpt = krs.callbacks.ModelCheckpoint('./temp/ckpt', monitor='val_categorical_accuracy', verbose=1,\n",
    "                                          save_best_only=True, save_weights_only=False, period=1)\n",
    "earlystop = krs.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.0001,\n",
    "                                             patience=3, verbose=1)\n",
    "# patience: n次acc未增长则终止训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-01T06:20:27.284255Z",
     "start_time": "2021-01-01T06:20:27.280170Z"
    }
   },
   "outputs": [],
   "source": [
    "# 衰减学习率\n",
    "class LearningRateExponentialDecay:\n",
    "    def __init__(self, initial_learning_rate, decay_epochs, decay_rate):\n",
    "        self.initial_learning_rate = initial_learning_rate\n",
    "        self.decay_epochs = decay_epochs\n",
    "        self.decay_rate = decay_rate\n",
    "\n",
    "    def __call__(self, epoch):\n",
    "        dtype = type(self.initial_learning_rate)\n",
    "        decay_epochs = np.array(self.decay_epochs).astype(dtype)\n",
    "        decay_rate = np.array(self.decay_rate).astype(dtype)\n",
    "        epoch = np.array(epoch).astype(dtype)\n",
    "        p = epoch / decay_epochs\n",
    "        learning_rate = self.initial_learning_rate * np.power(decay_rate, p)\n",
    "        return learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-01T06:20:27.646121Z",
     "start_time": "2021-01-01T06:20:27.643616Z"
    }
   },
   "outputs": [],
   "source": [
    "lr_schedule = LearningRateExponentialDecay(0.0003, EPOCH, 0.80)\n",
    "lr = krs.callbacks.LearningRateScheduler(lr_schedule, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-01T06:23:20.273185Z",
     "start_time": "2021-01-01T06:20:28.147979Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5800 samples, validate on 600 samples\n",
      "Epoch 1/25\n",
      "\n",
      "Epoch 00001: LearningRateScheduler setting learning rate to 0.0003.\n",
      "5800/5800 [==============================] - 12s 2ms/step - loss: 2.2857 - categorical_accuracy: 0.1557 - val_loss: 2.2547 - val_categorical_accuracy: 0.1567\n",
      "\n",
      "Epoch 00001: val_categorical_accuracy improved from -inf to 0.15667, saving model to ./temp/ckpt\n",
      "Epoch 2/25\n",
      "\n",
      "Epoch 00002: LearningRateScheduler setting learning rate to 0.0002973341922389158.\n",
      "5800/5800 [==============================] - 9s 2ms/step - loss: 2.2136 - categorical_accuracy: 0.1848 - val_loss: 2.1468 - val_categorical_accuracy: 0.2483\n",
      "\n",
      "Epoch 00002: val_categorical_accuracy improved from 0.15667 to 0.24833, saving model to ./temp/ckpt\n",
      "Epoch 3/25\n",
      "\n",
      "Epoch 00003: LearningRateScheduler setting learning rate to 0.0002946920729145618.\n",
      "5800/5800 [==============================] - 9s 2ms/step - loss: 2.0421 - categorical_accuracy: 0.2995 - val_loss: 1.9120 - val_categorical_accuracy: 0.3633\n",
      "\n",
      "Epoch 00003: val_categorical_accuracy improved from 0.24833 to 0.36333, saving model to ./temp/ckpt\n",
      "Epoch 4/25\n",
      "\n",
      "Epoch 00004: LearningRateScheduler setting learning rate to 0.0002920734315308764.\n",
      "5800/5800 [==============================] - 10s 2ms/step - loss: 1.7929 - categorical_accuracy: 0.3824 - val_loss: 1.7688 - val_categorical_accuracy: 0.3950\n",
      "\n",
      "Epoch 00004: val_categorical_accuracy improved from 0.36333 to 0.39500, saving model to ./temp/ckpt\n",
      "Epoch 5/25\n",
      "\n",
      "Epoch 00005: LearningRateScheduler setting learning rate to 0.00028947805946227145.\n",
      "5800/5800 [==============================] - 10s 2ms/step - loss: 1.6187 - categorical_accuracy: 0.4479 - val_loss: 1.6931 - val_categorical_accuracy: 0.4117\n",
      "\n",
      "Epoch 00005: val_categorical_accuracy improved from 0.39500 to 0.41167, saving model to ./temp/ckpt\n",
      "Epoch 6/25\n",
      "\n",
      "Epoch 00006: LearningRateScheduler setting learning rate to 0.0002869057499370111.\n",
      "5800/5800 [==============================] - 10s 2ms/step - loss: 1.4885 - categorical_accuracy: 0.4928 - val_loss: 1.6804 - val_categorical_accuracy: 0.4183\n",
      "\n",
      "Epoch 00006: val_categorical_accuracy improved from 0.41167 to 0.41833, saving model to ./temp/ckpt\n",
      "Epoch 7/25\n",
      "\n",
      "Epoch 00007: LearningRateScheduler setting learning rate to 0.00028435629802073855.\n",
      "5800/5800 [==============================] - 10s 2ms/step - loss: 1.3712 - categorical_accuracy: 0.5310 - val_loss: 1.6504 - val_categorical_accuracy: 0.4200\n",
      "\n",
      "Epoch 00007: val_categorical_accuracy improved from 0.41833 to 0.42000, saving model to ./temp/ckpt\n",
      "Epoch 8/25\n",
      "\n",
      "Epoch 00008: LearningRateScheduler setting learning rate to 0.00028182950060014905.\n",
      "5800/5800 [==============================] - 10s 2ms/step - loss: 1.2657 - categorical_accuracy: 0.5729 - val_loss: 1.6515 - val_categorical_accuracy: 0.4400\n",
      "\n",
      "Epoch 00008: val_categorical_accuracy improved from 0.42000 to 0.44000, saving model to ./temp/ckpt\n",
      "Epoch 9/25\n",
      "\n",
      "Epoch 00009: LearningRateScheduler setting learning rate to 0.0002793251563668079.\n",
      "5800/5800 [==============================] - 10s 2ms/step - loss: 1.1736 - categorical_accuracy: 0.6060 - val_loss: 1.6598 - val_categorical_accuracy: 0.4233\n",
      "\n",
      "Epoch 00009: val_categorical_accuracy did not improve from 0.44000\n",
      "Epoch 10/25\n",
      "\n",
      "Epoch 00010: LearningRateScheduler setting learning rate to 0.00027684306580111226.\n",
      "5800/5800 [==============================] - 10s 2ms/step - loss: 1.0671 - categorical_accuracy: 0.6469 - val_loss: 1.6724 - val_categorical_accuracy: 0.4317\n",
      "\n",
      "Epoch 00010: val_categorical_accuracy did not improve from 0.44000\n",
      "Epoch 11/25\n",
      "\n",
      "Epoch 00011: LearningRateScheduler setting learning rate to 0.0002743830311563958.\n",
      "5800/5800 [==============================] - 10s 2ms/step - loss: 0.9889 - categorical_accuracy: 0.6747 - val_loss: 1.6727 - val_categorical_accuracy: 0.4417\n",
      "\n",
      "Epoch 00011: val_categorical_accuracy improved from 0.44000 to 0.44167, saving model to ./temp/ckpt\n",
      "Epoch 12/25\n",
      "\n",
      "Epoch 00012: LearningRateScheduler setting learning rate to 0.00027194485644317407.\n",
      "5800/5800 [==============================] - 9s 2ms/step - loss: 0.8898 - categorical_accuracy: 0.7136 - val_loss: 1.7182 - val_categorical_accuracy: 0.4517\n",
      "\n",
      "Epoch 00012: val_categorical_accuracy improved from 0.44167 to 0.45167, saving model to ./temp/ckpt\n",
      "Epoch 13/25\n",
      "\n",
      "Epoch 00013: LearningRateScheduler setting learning rate to 0.0002695283474135303.\n",
      "5800/5800 [==============================] - 10s 2ms/step - loss: 0.8184 - categorical_accuracy: 0.7400 - val_loss: 1.7673 - val_categorical_accuracy: 0.4650\n",
      "\n",
      "Epoch 00013: val_categorical_accuracy improved from 0.45167 to 0.46500, saving model to ./temp/ckpt\n",
      "Epoch 14/25\n",
      "\n",
      "Epoch 00014: LearningRateScheduler setting learning rate to 0.0002671333115456397.\n",
      "5800/5800 [==============================] - 10s 2ms/step - loss: 0.7680 - categorical_accuracy: 0.7559 - val_loss: 1.7722 - val_categorical_accuracy: 0.4700\n",
      "\n",
      "Epoch 00014: val_categorical_accuracy improved from 0.46500 to 0.47000, saving model to ./temp/ckpt\n",
      "Epoch 15/25\n",
      "\n",
      "Epoch 00015: LearningRateScheduler setting learning rate to 0.0002647595580284314.\n",
      "5800/5800 [==============================] - 10s 2ms/step - loss: 0.6948 - categorical_accuracy: 0.7900 - val_loss: 1.8450 - val_categorical_accuracy: 0.4650\n",
      "\n",
      "Epoch 00015: val_categorical_accuracy did not improve from 0.47000\n",
      "Epoch 16/25\n",
      "\n",
      "Epoch 00016: LearningRateScheduler setting learning rate to 0.00026240689774638675.\n",
      "5800/5800 [==============================] - 10s 2ms/step - loss: 0.6426 - categorical_accuracy: 0.8062 - val_loss: 1.9405 - val_categorical_accuracy: 0.4667\n",
      "\n",
      "Epoch 00016: val_categorical_accuracy did not improve from 0.47000\n",
      "Epoch 17/25\n",
      "\n",
      "Epoch 00017: LearningRateScheduler setting learning rate to 0.00026007514326447225.\n",
      "5800/5800 [==============================] - 10s 2ms/step - loss: 0.5923 - categorical_accuracy: 0.8195 - val_loss: 1.8909 - val_categorical_accuracy: 0.4650\n",
      "\n",
      "Epoch 00017: val_categorical_accuracy did not improve from 0.47000\n",
      "Epoch 00017: early stopping\n"
     ]
    }
   ],
   "source": [
    "lr_schedule = LearningRateExponentialDecay(0.0003, EPOCH, 0.80)\n",
    "lr = krs.callbacks.LearningRateScheduler(lr_schedule, verbose=1)\n",
    "history = model.fit(x=text_processed, y=dummy_target, batch_size=BATCH_SIZE,\n",
    "                    epochs=EPOCH, validation_data=(text_processed_val, dummy_target_val),\n",
    "                    callbacks=[ckpt, earlystop, lr], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-01T06:09:41.807108Z",
     "start_time": "2021-01-01T06:09:41.644938Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()  # 初始化画布\n",
    "N = [i for i in range(len(history.history['loss']))]  # 取横坐标的值\n",
    "plt.plot(N, history.history['loss'], label='train_loss')  # 绘制训练loss的折线图\n",
    "plt.scatter(N, history.history['loss'])  # 绘制训练loss的散点图\n",
    "plt.plot(N, history.history['val_loss'], label='val_loss')\n",
    "plt.scatter(N, history.history['val_loss'])\n",
    "plt.xlabel('Epoch #')  # 设置坐标轴名称\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()  # 显示图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-01T06:05:06.773089Z",
     "start_time": "2021-01-01T06:05:06.473996Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 490us/step\n",
      "[1.8880992380777994, 0.4650000035762787]\n"
     ]
    }
   ],
   "source": [
    "metrics=model.evaluate(x=text_processed_val, y=dummy_target_val, verbose=1)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-01T06:05:08.276693Z",
     "start_time": "2021-01-01T06:05:08.274784Z"
    }
   },
   "outputs": [],
   "source": [
    "# 查看val_set上的 acc, 与上面metric一致"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-01T06:05:10.166646Z",
     "start_time": "2021-01-01T06:05:09.159872Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.465\n"
     ]
    }
   ],
   "source": [
    "def check_accuracy(ture_lables, predict_lables):\n",
    "    num = 0\n",
    "    for i in range(len(ture_lables)):\n",
    "        if int(ture_lables[i]) == predict_lables[i]:\n",
    "            num += 1\n",
    "    return num/len(ture_lables)\n",
    "\n",
    "y_val = np.argmax(model.predict(text_processed_val), axis=1)\n",
    "y_val = list(y_val)\n",
    "\n",
    "print(check_accuracy(labels_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-01T06:05:10.274824Z",
     "start_time": "2021-01-01T06:05:10.272681Z"
    }
   },
   "outputs": [],
   "source": [
    "# 预测lables 的分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-01T06:05:11.260905Z",
     "start_time": "2021-01-01T06:05:11.137433Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAARkElEQVR4nO3df4xV5Z3H8fd3B5WFpcHibNtldIdNiAV1AB0ouzRtca0F3Cwm3TS0ahNbS0x1a822W3YT/KOmCX80m10sllCXTRqLmlRNyTpVt7trzFYxDJUo+KNSZOUuNgIt1lopoN/9Yy7mOl6cMzB3LvPM+5VM5p7nPM853zMwnznz3HPORGYiSSrXH7S7AElSaxn0klQ4g16SCmfQS1LhDHpJKtyEdhfQzDnnnJPd3d3tLkOSxoxt27YdyMzOZutOy6Dv7u6mv7+/3WVI0pgREf97onVO3UhS4Qx6SSqcQS9JhTst5+ibOXr0KLVajcOHD7e7lDFl4sSJdHV1ccYZZ7S7FEltMmaCvlarMWXKFLq7u4mIdpczJmQmBw8epFarMWPGjHaXI6lNxszUzeHDh5k2bZohPwwRwbRp0/wtSBrnxkzQA4b8SfBrJqlS0EfEkoh4PiJ2RcSqJuuvioin6h+PRcSchnV7IuLpiNgeEV4cL0mjbMg5+ojoANYBnwRqwNaI2JyZzzR0exH4eGb+OiKWAhuAjzSsX5yZB0awbrpXPTCSm2PPmitGdHuSdLqo8mbsAmBXZu4GiIi7geXA20GfmY819N8CdI1kkaeDQ4cOsWnTJr785S8Pa9yyZcvYtGkTU6dObU1hwPbt29m3bx/Lli1r2T4kDe1UT0BbdcJZZepmOrC3YblWbzuRLwI/blhO4OGI2BYRK080KCJWRkR/RPTv37+/Qlmj69ChQ9x+++3van/zzTffc1xfX19LQx4Ggr6vr6+l+5A0dlUJ+mbv5jX9+4MRsZiBoP9GQ/OizLwYWArcEBEfazY2MzdkZm9m9nZ2Nn0uT1utWrWKX/ziF8ydO5f58+ezePFiPve5z3HRRRcBcOWVV3LJJZdwwQUXsGHDhrfHdXd3c+DAAfbs2cOsWbP40pe+xAUXXMDll1/OG2+8ccL9rV27ltmzZ9PT08OKFSsAeP311/nCF77A/PnzmTdvHj/60Y84cuQIt9xyC/fccw9z587lnnvuae0XQtKYU2Xqpgac27DcBewb3CkieoA7gKWZefB4e2buq39+JSLuZ2Aq6NFTKbod1qxZw44dO9i+fTuPPPIIV1xxBTt27Hj7+vSNGzfy/ve/nzfeeIP58+fz6U9/mmnTpr1jGy+88AJ33XUX3/ve9/jMZz7Dvffey9VXX33C/b344oucddZZHDp0CIBvfetbXHrppWzcuJFDhw6xYMECLrvsMr75zW/S39/Pd77znZZ+DSSNTVXO6LcCMyNiRkScCawANjd2iIjzgPuAazLz5w3tkyNiyvHXwOXAjpEqvp0WLFjwjpuQ1q5dy5w5c1i4cCF79+7lhRdeeNeYGTNmMHfuXAAuueQS9uzZc8Lt9/T0cNVVV3HnnXcyYcLAz+OHH36YNWvWMHfuXD7xiU9w+PBhXnrppRE9LknlGfKMPjOPRcSNwENAB7AxM3dGxPX19euBW4BpwO3167aPZWYv8AHg/nrbBGBTZj7YkiMZZZMnT3779SOPPMJPfvITHn/8cSZNmvR2CA921llnvf26o6PjPaduHnjgAR599FE2b97Mrbfeys6dO8lM7r33Xs4///x39H3iiSdG4IgklarSIxAysw/oG9S2vuH1dcB1TcbtBuYMbh8Jo3055JQpU3jttdearnv11Vc5++yzmTRpEs899xxbtmw5pX299dZb7N27l8WLF/PRj36UTZs28dvf/pZPfepT3Hbbbdx2221EBE8++STz5s17z9okaUzdGdtO06ZNY9GiRVx44YV8/etff8e6JUuWcOzYMXp6eli9ejULFy48pX29+eabXH311Vx00UXMmzePm2++malTp7J69WqOHj1KT08PF154IatXrwZg8eLFPPPMM74ZK6mpyGx6AU1b9fb25uC/MPXss88ya9asNlU0tvm1k0ZHO6+jj4ht9Snzd/GMXpIKN2YeU1yqG264gZ/+9KfvaLvpppu49tpr21SRpNKMqaDPzOKexrhu3bqWbv90nJqTNLrGzNTNxIkTOXjwoME1DMf/8MjEiRPbXYqkNhozZ/RdXV3UajVOx+fgnM6O/ylBSePXmAn6M844wz+HJ0knYcxM3UiSTo5BL0mFM+glqXAGvSQVzqCXpMIZ9JJUOINekgpn0EtS4Qx6SSqcQS9JhTPoJalwBr0kFc6gl6TCGfSSVDiDXpIKZ9BLUuEMekkqnEEvSYUz6CWpcAa9JBXOoJekwhn0klQ4g16SCmfQS1LhKgV9RCyJiOcjYldErGqy/qqIeKr+8VhEzKk6VpLUWkMGfUR0AOuApcBs4LMRMXtQtxeBj2dmD3ArsGEYYyVJLVTljH4BsCszd2fmEeBuYHljh8x8LDN/XV/cAnRVHStJaq0qQT8d2NuwXKu3ncgXgR8Pd2xErIyI/ojo379/f4WyJElVVAn6aNKWTTtGLGYg6L8x3LGZuSEzezOzt7Ozs0JZkqQqJlToUwPObVjuAvYN7hQRPcAdwNLMPDicsZKk1qlyRr8VmBkRMyLiTGAFsLmxQ0ScB9wHXJOZPx/OWElSaw15Rp+ZxyLiRuAhoAPYmJk7I+L6+vr1wC3ANOD2iAA4Vp+GaTq2RcciSWqiytQNmdkH9A1qW9/w+jrguqpjJUmjxztjJalwBr0kFc6gl6TCGfSSVDiDXpIKZ9BLUuEMekkqnEEvSYUz6CWpcAa9JBXOoJekwhn0klQ4g16SCmfQS1LhDHpJKpxBL0mFM+glqXAGvSQVzqCXpMIZ9JJUOINekgpn0EtS4Qx6SSqcQS9JhTPoJalwBr0kFc6gl6TCGfSSVDiDXpIKZ9BLUuEMekkqnEEvSYWrFPQRsSQino+IXRGxqsn6D0fE4xHx+4j42qB1eyLi6YjYHhH9I1W4JKmaCUN1iIgOYB3wSaAGbI2IzZn5TEO3XwFfAa48wWYWZ+aBU6xVknQSqpzRLwB2ZebuzDwC3A0sb+yQma9k5lbgaAtqlCSdgipBPx3Y27Bcq7dVlcDDEbEtIlaeqFNErIyI/ojo379//zA2L0l6L1WCPpq05TD2sSgzLwaWAjdExMeadcrMDZnZm5m9nZ2dw9i8JOm9VAn6GnBuw3IXsK/qDjJzX/3zK8D9DEwFSZJGSZWg3wrMjIgZEXEmsALYXGXjETE5IqYcfw1cDuw42WIlScM35FU3mXksIm4EHgI6gI2ZuTMirq+vXx8RHwT6gfcBb0XEV4HZwDnA/RFxfF+bMvPBlhyJJKmpIYMeIDP7gL5BbesbXv+SgSmdwX4DzDmVAiVJp8Y7YyWpcAa9JBXOoJekwhn0klQ4g16SCmfQS1LhDHpJKpxBL0mFM+glqXAGvSQVzqCXpMIZ9JJUOINekgpn0EtS4Qx6SSqcQS9JhTPoJalwBr0kFc6gl6TCGfSSVLhKfxx8LOle9cApjd+z5ooRqkTSaPP7vznP6CWpcAa9JBXOoJekwhn0klQ4g16SCmfQS1LhDHpJKpxBL0mFK+6GKamdvGFHpyPP6CWpcAa9JBWuUtBHxJKIeD4idkXEqibrPxwRj0fE7yPia8MZK0lqrSGDPiI6gHXAUmA28NmImD2o26+ArwDfPomxkqQWqnJGvwDYlZm7M/MIcDewvLFDZr6SmVuBo8MdK0lqrSpBPx3Y27Bcq7dVcSpjJUkjoErQR5O2rLj9ymMjYmVE9EdE//79+ytuXpI0lCpBXwPObVjuAvZV3H7lsZm5ITN7M7O3s7Oz4uYlSUOpEvRbgZkRMSMizgRWAJsrbv9UxkqSRsCQd8Zm5rGIuBF4COgANmbmzoi4vr5+fUR8EOgH3ge8FRFfBWZn5m+ajW3RsUiSmqj0CITM7AP6BrWtb3j9SwamZSqNlSSNHu+MlaTCGfSSVDiDXpIKZ9BLUuF8Hr1UEJ+Hr2Y8o5ekwhn0klQ4g16SCmfQS1LhDHpJKpxX3UgaMV71c3ryjF6SCmfQS1LhDHpJKpxBL0mFM+glqXAGvSQVzqCXpMIZ9JJUOINekgpn0EtS4Qx6SSqcz7pRUXzWivRuntFLUuEMekkqnEEvSYVzjr4wzlFLGsyg14jyB410+nHqRpIKZ9BLUuEMekkqnEEvSYWrFPQRsSQino+IXRGxqsn6iIi19fVPRcTFDev2RMTTEbE9IvpHsnhJ0tCGvOomIjqAdcAngRqwNSI2Z+YzDd2WAjPrHx8Bvlv/fNzizDwwYlVLkiqrcka/ANiVmbsz8whwN7B8UJ/lwPdzwBZgakR8aIRrlSSdhCpBPx3Y27Bcq7dV7ZPAwxGxLSJWnmyhkqSTU+WGqWjSlsPosygz90XEHwP/ERHPZeaj79rJwA+BlQDnnXdehbIkSVVUOaOvAec2LHcB+6r2yczjn18B7mdgKuhdMnNDZvZmZm9nZ2e16iVJQ6oS9FuBmRExIyLOBFYAmwf12Qx8vn71zULg1cx8OSImR8QUgIiYDFwO7BjB+iVJQxhy6iYzj0XEjcBDQAewMTN3RsT19fXrgT5gGbAL+B1wbX34B4D7I+L4vjZl5oMjfhSSpBOq9FCzzOxjIMwb29Y3vE7ghibjdgNzTrHGMcWHekk63XhnrCQVzqCXpMIZ9JJUOINekgpn0EtS4Qx6SSqcQS9JhTPoJalwBr0kFc6gl6TCGfSSVDiDXpIKZ9BLUuEMekkqnEEvSYUz6CWpcAa9JBXOoJekwhn0klQ4g16SCmfQS1LhDHpJKpxBL0mFM+glqXAGvSQVzqCXpMIZ9JJUOINekgpn0EtS4Qx6SSqcQS9JhTPoJalwBr0kFa5S0EfEkoh4PiJ2RcSqJusjItbW1z8VERdXHStJaq0hgz4iOoB1wFJgNvDZiJg9qNtSYGb9YyXw3WGMlSS1UJUz+gXArszcnZlHgLuB5YP6LAe+nwO2AFMj4kMVx0qSWigy8707RPwNsCQzr6svXwN8JDNvbOjz78CazPyf+vJ/At8Auoca27CNlQz8NgBwPvD8qR3aCZ0DHGjRtscCj9/j9/jL9KeZ2dlsxYQKg6NJ2+CfDifqU2XsQGPmBmBDhXpOSUT0Z2Zvq/dzuvL4PX6Pf/wdf5WgrwHnNix3Afsq9jmzwlhJUgtVmaPfCsyMiBkRcSawAtg8qM9m4PP1q28WAq9m5ssVx0qSWmjIM/rMPBYRNwIPAR3AxszcGRHX19evB/qAZcAu4HfAte81tiVHUl3Lp4dOcx7/+Obxj0NDvhkrSRrbvDNWkgpn0EtS4cZN0I/nRzFExLkR8d8R8WxE7IyIm9pdUztEREdEPFm/72PciYipEfHDiHiu/n/hz9td02iKiJvr//93RMRdETGx3TWNlnER9D6KgWPA32XmLGAhcMM4O/7jbgKebXcRbfQvwIOZ+WFgDuPoaxER04GvAL2ZeSEDF4esaG9Vo2dcBD3j/FEMmflyZv6s/vo1Br7Bp7e3qtEVEV3AFcAd7a6lHSLifcDHgH8FyMwjmXmorUWNvgnAH0bEBGAS4+ienvES9NOBvQ3LNcZZ0B0XEd3APOCJNpcy2v4Z+HvgrTbX0S5/BuwH/q0+fXVHRExud1GjJTP/D/g28BLwMgP3+jzc3qpGz3gJ+sqPYihZRPwRcC/w1cz8TbvrGS0R8VfAK5m5rd21tNEE4GLgu5k5D3gdGDfvVUXE2Qz8Fj8D+BNgckRc3d6qRs94Cfoqj3EoWkScwUDI/yAz72t3PaNsEfDXEbGHgWm7SyPizvaWNOpqQC0zj/8m90MGgn+8uAx4MTP3Z+ZR4D7gL9pc06gZL0E/rh/FEBHBwNzss5n5T+2uZ7Rl5j9kZldmdjPwb/9fmTluzuYAMvOXwN6IOL/e9JfAM20sabS9BCyMiEn174e/ZBy9GV3loWZj3mn6KIbRtAi4Bng6IrbX2/4xM/vaV5La4G+BH9RPdnZTf1TJeJCZT0TED4GfMXAV2pOMo8ch+AgESSrceJm6kaRxy6CXpMIZ9JJUOINekgpn0EtS4Qx6SSqcQS9Jhft/N3sxw+3602IAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels_id = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "x = [i for i in range(len(labels_id))]\n",
    "count_in_train = [y_val.count(label) / len(y_val) for label in range(10)]  # 统计训练集占比\n",
    "plt.figure()\n",
    "plt.bar(x, count_in_train, width=0.5, label=\"train_set\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-28T17:00:06.779748Z",
     "start_time": "2020-12-28T17:00:06.743704Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save('./temp/tf_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-01T05:21:36.712572Z",
     "start_time": "2021-01-01T05:21:33.783667Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOAD DONE\n"
     ]
    }
   ],
   "source": [
    "model_loaded = krs.models.load_model('./temp/ckpt')\n",
    "print('LOAD DONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-01T05:45:34.439605Z",
     "start_time": "2021-01-01T05:45:34.436213Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_test_data(filename):\n",
    "    text_list = []\n",
    "    print(\"正在加载文本测试数据...\")\n",
    "    with open(filename, \"r\") as f:\n",
    "        for line in f.readlines():\n",
    "            item = line.strip().split('\\t')\n",
    "            text_list.append(item[0])\n",
    "        \n",
    "    print(\"共加载了 %s 条数据\" % len(text_list))\n",
    "    return text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-01T05:45:35.197796Z",
     "start_time": "2021-01-01T05:45:35.190857Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在加载文本测试数据...\n",
      "共加载了 1600 条数据\n"
     ]
    }
   ],
   "source": [
    "# 读取测试集\n",
    "test_data_path = '../data/test_processed.txt'\n",
    "\n",
    "texts_test = load_test_data(test_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-01T05:45:36.996528Z",
     "start_time": "2021-01-01T05:45:36.993232Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The body of her nephew was in a suitcase under the bed'"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-01T05:45:41.580956Z",
     "start_time": "2021-01-01T05:45:41.523549Z"
    }
   },
   "outputs": [],
   "source": [
    "texts_test = [\".\".join(t.split(' ')) for t in texts_test]\n",
    "\n",
    "\n",
    "text_processed_test = np.array(list(vocab_processor.fit_transform(texts_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-01T05:45:42.028761Z",
     "start_time": "2021-01-01T05:45:42.025603Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  2,  3,  4,  5,  6,  7,  8,  9, 10,  1, 11,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_processed_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-01T05:22:08.502136Z",
     "start_time": "2021-01-01T05:22:07.515274Z"
    }
   },
   "outputs": [],
   "source": [
    "y_prob = model_loaded.predict(text_processed_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-01T05:45:48.886589Z",
     "start_time": "2021-01-01T05:45:48.109328Z"
    }
   },
   "outputs": [],
   "source": [
    "y_prob = model.predict(text_processed_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-01T05:45:49.613989Z",
     "start_time": "2021-01-01T05:45:49.610445Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 4 4 7 1 9 0 2 9 4 0 7 9 7 2 7 2 2 9 7 8 8 6 9 1 9 7 9 9 2 3 5 0 0 9 0 7\n",
      " 4 5 2 3 2 2 9 3 6 4 9 3 4 9 9 9 0 9 7 0 1 9 9 5 7 0 5 1 9 9 5 0 9 1 6 0 3\n",
      " 3 6 2 9 6 6 6 9 8 2 4 6 4 7 9 9 4 9 4 9 1 6 9 1 8 0]\n"
     ]
    }
   ],
   "source": [
    "y_pre = np.argmax(y_prob, axis=1)\n",
    "print(y_pre[:100])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T11:12:02.413009Z",
     "start_time": "2021-01-04T11:12:02.237275Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "labels_id = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "x = [i for i in range(len(labels_id))]\n",
    "count_in_train = [y_test.count(label) / len(y_test) for label in range(10)]  # 统计训练集占比\n",
    "plt.figure()\n",
    "plt.bar(x, count_in_train, width=0.5, label=\"test_set\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  The ture accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-29T00:24:35.851513Z",
     "start_time": "2020-12-29T00:24:35.847979Z"
    }
   },
   "outputs": [],
   "source": [
    "int(labels_val[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-29T01:05:45.493999Z",
     "start_time": "2020-12-29T01:05:45.361024Z"
    }
   },
   "outputs": [],
   "source": [
    "labels_id = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "x = [i for i in range(len(labels_id))]\n",
    "count_in_train = [y_val.count(label) / len(y_val) for label in range(10)]  # 统计训练集占比\n",
    "plt.figure()\n",
    "plt.bar(x, count_in_train, width=0.5, label=\"train_set\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-29T00:24:57.668743Z",
     "start_time": "2020-12-29T00:24:57.665992Z"
    }
   },
   "outputs": [],
   "source": [
    "print(y_test[1:100])\n",
    "print(y_val[1:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lable on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-28T17:11:17.161902Z",
     "start_time": "2020-12-28T17:11:17.158100Z"
    }
   },
   "outputs": [],
   "source": [
    "y_test = list(y_pre)\n",
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-28T17:11:18.420010Z",
     "start_time": "2020-12-28T17:11:18.290786Z"
    }
   },
   "outputs": [],
   "source": [
    "labels_id = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "x = [i for i in range(len(labels_id))]\n",
    "count_in_train = [y_test.count(label) / len(y_test) for label in range(10)]  # 统计训练集占比\n",
    "plt.figure()\n",
    "plt.bar(x, count_in_train, width=0.5, label=\"train_set\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-28T16:54:54.434607Z",
     "start_time": "2020-12-28T16:54:54.428558Z"
    }
   },
   "outputs": [],
   "source": [
    "count_in_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T09:58:54.634149Z",
     "start_time": "2021-01-04T09:58:54.631702Z"
    }
   },
   "outputs": [],
   "source": [
    "# 定义类别列表\n",
    "LABEL_INDEX = ['Cause-Effect', 'Instrument-Agency', 'Product-Producer',\n",
    "               'Content-Container', 'Entity-Origin', 'Entity-Destination',\n",
    "               'Component-Whole', 'Member-Collection', 'Message-Topic', 'Other']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T11:12:11.476640Z",
     "start_time": "2021-01-04T11:12:11.471594Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('./result/results.txt','w', encoding='utf-8') as f:\n",
    "    for i in range(len(y_test)):\n",
    "        line = LABEL_INDEX[int(y_test[i])]\n",
    "        f.write(str(line) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-28T15:20:47.655433Z",
     "start_time": "2020-12-28T15:20:47.647781Z"
    }
   },
   "outputs": [],
   "source": [
    "result_text = []\n",
    "with open('./result/results.txt','r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        text =line.strip().split('\\n')\n",
    "        text = text[0]\n",
    "        result_text.append(text)\n",
    "        \n",
    "print(len(result_text),result_text[1:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = krs.layers.Embedding(len(dict.items()),\n",
    "                embedding_size, input_length = max_sequence_length,\n",
    "                 mask_zero= True    )\n",
    "#print(type(text_processed[:4]),input_text.shape,text_processed.shape)\n",
    "input_text = text_processed[:4]\n",
    "#output = temp(input_text)\n",
    "embedding = krs.layers.Embedding(input_dim=5000, output_dim=16, mask_zero=True)\n",
    "\n",
    "masked_output = embedding(padded_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_inputs = [\n",
    "    [711, 632, 71],\n",
    "    [73, 8, 3215, 55, 927],\n",
    "    [83, 91, 1, 645, 1253, 927],\n",
    "]\n",
    "\n",
    "# By default, this will pad using 0s; it is configurable via the\n",
    "# \"value\" parameter.\n",
    "# Note that you could \"pre\" padding (at the beginning) or\n",
    "# \"post\" padding (at the end).\n",
    "# We recommend using \"post\" padding when working with RNN layers\n",
    "# (in order to be able to use the\n",
    "# CuDNN implementation of the layers).\n",
    "padded_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    raw_inputs, padding=\"post\"\n",
    ")\n",
    "print(padded_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path):\n",
    "    label_list, text_list = [], []\n",
    "    k = 0\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        for line in f :\n",
    "            k += 1\n",
    "            text = line.strip().split('\\t')\n",
    "            label_list.append(labels_dict[text[2]]) #返回label的值\n",
    "            #print(k)\n",
    "            #print(line)\n",
    "            text_list.append(text[3])\n",
    "    return text_list, label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-27T03:51:30.328265Z",
     "start_time": "2020-12-27T03:51:30.267668Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 419.3333332538605,
   "position": {
    "height": "767.9791870117188px",
    "left": "1064.666748046875px",
    "right": "20px",
    "top": "165px",
    "width": "484.2708435058594px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
